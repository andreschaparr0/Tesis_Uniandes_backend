\chapter{Marco Teórico}
\label{chap:marco-teorico}

Este capítulo presenta los fundamentos teóricos que sustentan el desarrollo del sistema de recomendación de hojas de vida. Se abordan conceptos clave para el desarrollo de la tesis principalmente en el procesamiento de lenguaje natural y en los modelos de lenguaje y extracción de información.

\section{Procesamiento de Lenguaje Natural}

El procesamiento de lenguaje natural (NLP) es una disciplina que combina lingüística, informática e inteligencia artificial para dotar a las máquinas de la capacidad de entender, interpretar y generar lenguaje humano \cite{jurafsky2023speech}. En el contexto de este trabajo, las técnicas de NLP son fundamentales para transformar documentos no estructurados (HVs en formato PDF) en representaciones estructuradas que permitan análisis automatizado.

\subsection{Extracción y Limpieza de Texto}

La extracción y limpieza de texto son procesos fundamentales en el análisis automático de documentos. La extracción se refiere a recuperar el contenido textual de un archivo, el cual puede encontrarse estructurado o representar texto a través de imágenes que requieren técnicas de reconocimiento óptico de caracteres. Una vez obtenido el contenido, la etapa de limpieza busca normalizarlo y eliminar inconsistencias propias de la digitalización o del formato, como caracteres irregulares, fragmentación de palabras o elementos considerados ruido. Estas transformaciones permiten obtener un texto coherente y uniforme que pueda ser utilizado en posteriores tareas de procesamiento y análisis.


\section{Modelos de Lenguaje y Extracción de Información}

Esta sección describe cómo los modelos de lenguaje y las prácticas de diseño de \emph{prompts} permiten transformar texto libre en representaciones estructuradas útiles para el sistema: primero se presentan las capacidades de los LLMs para comprender contexto y semántica; luego se explica cómo, mediante \emph{prompt engineering} y un framework de python, se obtienen salidas en formatos controlados (p.\,ej., JSON) que alimentan los módulos de estructuración y comparaciónn.

\subsection{Modelos de Lenguaje Grandes (LLMs)}

Los modelos de lenguaje grandes son sistemas de aprendizaje profundo entrenados con grandes volúmenes de texto, capaces de aprender representaciones complejas del lenguaje y comprender su contexto y semántica. En este trabajo se emplea GPT-4o-mini, un modelo de la familia GPT (Generative Pre-trained Transformer) desarrollado por OpenAI y desplegado a través de Azure OpenAI Services. Estos modelos pueden generar respuestas estructuradas a partir de instrucciones bien definidas y adaptarse a distintos dominios o tareas con un ajuste mínimo.


\subsection{Prompt Engineering}

El \emph{prompt engineering} consiste en diseñar instrucciones que guían a los modelos de lenguaje para generar resultados precisos y estructurados. En tareas de extracción y organización de información, esta práctica permite definir con claridad el formato de salida y descomponer procesos complejos en pasos intermedios. Al incluir ejemplos dentro del propio prompt, el modelo puede adaptarse mejor al contexto y producir respuestas más consistentes. Para la orquestación de estas interacciones se emplea LangChain \cite{langchain}, un framework que permite gestionar plantillas de prompts, estructurar las respuestas mediante parsers, manejar errores y conectar distintos proveedores de modelos.




\subsection{LangChain}

LangChain es un framework diseñado para facilitar la construcción de aplicaciones basadas en modelos de lenguaje mediante la definición de cadenas de procesamiento, plantillas de prompts reutilizables y mecanismos de estandarización de entradas y salidas. Además, incorpora herramientas para validar formatos de salida, integrar proveedores externos de modelos y gestionar parámetros de ejecución de forma consistente. Estas características lo convierten en una plataforma adecuada para desarrollar sistemas que requieran orquestar interacciones complejas con modelos de lenguaje de manera reproducible y controlada.\cite{langchain}

