\chapter{Estado del Arte}
\label{chap:estado-del-arte}

\section{Sistemas de Recomendación de Talento}
Los sistemas de recomendación de talento buscan apoyar el emparejamiento entre candidatos y vacantes, reduciendo el esfuerzo manual y mejorando la calidad de la preselección. En la literatura, la mayoría de enfoques para emparejar HV--puesto se enmarcan en la recomendación basada en contenido \cite{ricci2011introduction}, donde se construye una representación de los perfiles (competencias, experiencia, educación) y de las descripciones de cargo (requisitos, responsabilidades) para medir su similitud. Desde la práctica industrial, muchas soluciones se integran en sistemas de seguimiento de candidatos (ATS), combinando extracción de información, normalización de atributos y reglas de filtrado (palabras clave, años de experiencia, ubicación) con técnicas de ranking.

Enfoques clásicos han utilizado modelos de bolsa de palabras y TF--IDF para comparar HVs y descripciones mediante medidas como la similitud de coseno, mientras que trabajos más recientes incorporan representaciones densas (embeddings) entrenadas sobre grandes corpus, lo que permite capturar relaciones semánticas entre términos. En paralelo, se han propuesto métodos basados en ontologías o catálogos de habilidades (p.\,ej., taxonomías de roles y competencias) para homogeneizar vocabularios y realizar coincidencias a un nivel conceptual. Más recientemente, los modelos de lenguaje grandes (LLMs) se han explorado como una alternativa flexible para extraer atributos, inferir habilidades y generar explicaciones del ajuste candidato--puesto, especialmente en escenarios con datos limitados o heterogéneos.

Sin embargo, varios trabajos coinciden en señalar desafíos persistentes: la dificultad de manejar HVs y descripciones en formatos variados, la necesidad de explicabilidad (justificar por qué un candidato aparece mejor posicionado) y la gestión de sesgos en los datos de entrenamiento o en las reglas de negocio. El sistema propuesto en esta tesis se posiciona en este espacio como un enfoque basado en contenido que explota LLMs para estructurar información y realizar comparaciones por aspectos, con énfasis en transparencia del desglose de puntajes y en un dominio específico (perfiles tecnológicos) en lugar de cubrir todos los tipos de cargos.

\section{Extracción y Estructuración de HVs}
La extracción y estructuración de información a partir de HVs y descripciones de trabajo ha sido abordada tradicionalmente mediante pipelines de NLP que combinan extracción de texto (OCR o lectura directa de PDFs), normalización, segmentación en secciones (datos personales, educación, experiencia, habilidades) y técnicas de reconocimiento de entidades nombradas (NER) para identificar instituciones, cargos, tecnologías e intervalos de tiempo \cite{jurafsky2023speech}. En estos enfoques, la representación resultante se almacena en esquemas estructurados (tablas o documentos JSON) que facilitan consultas y comparaciones posteriores. No obstante, la gran variedad de formatos de HVs (diseños gráficos, columnas, idiomas, niveles de detalle) y de descripciones de cargo introduce ruido y vacíos de información que dificultan la automatización completa.

Con la aparición de representaciones densas y modelos de lenguaje más potentes, se han propuesto métodos que utilizan \emph{embeddings} para representar secciones completas de la HV o del anuncio de trabajo, o que aplican modelos como BERT y derivados para tareas de NER y clasificación de secciones \cite{mikolov2013word2vec,devlin2019bert,reimers2019sentence}. Más recientemente, los LLMs se han utilizado directamente para extraer estructuras de alto nivel (p.\,ej., transformar texto libre a JSON siguiendo un esquema predefinido), lo que reduce la necesidad de reglas específicas por formato a costa de introducir dependencias de proveedor, costes y variabilidad en la salida. En este contexto, el presente trabajo adopta un enfoque híbrido: combina extracción y limpieza clásica con una capa de estructuración basada en prompts y LLMs, usando un esquema de campos claramente definido para CVs y Jobs que se alinea con los aspectos de comparación.

\section{Evaluación y Métricas}
La evaluación de sistemas de recomendación de talento suele seguir prácticas heredadas de la evaluación de sistemas de recomendación y de recuperación de información: cuando se dispone de etiquetas de relevancia (p.\,ej., candidatos aceptados/rechazados o rankings emitidos por expertos), se utilizan métricas como precisión en el top-\(k\), MAP, NDCG o correlaciones de rangos (Spearman, Kendall) entre el orden generado por el sistema y el de referencia \cite{ricci2011introduction}. En contextos de emparejamiento HV--puesto también se reportan tasas de acierto sobre un conjunto reducido de candidatos o análisis de \emph{hit-rate} en posiciones altas del ranking. Sin embargo, en muchos escenarios reales los datos etiquetados son escasos y las etiquetas pueden estar sujetas a sesgos históricos, lo que limita la aplicabilidad directa de estas métricas.

Por otra parte, en tareas de extracción y estructuración, resulta habitual evaluar la calidad de los campos extraídos mediante medidas de exactitud a nivel de entidad (precisión, cobertura y F1 sobre NER o sobre la identificación de secciones) y, más recientemente, mediante calificaciones humanas en escalas discretas cuando se emplean LLMs para producir estructuras complejas. En este trabajo, dado el tamaño acotado del conjunto de datos y el énfasis en un prototipo funcional, se opta por una evaluación mixta basada en juicio experto: (i) valoración manual de la calidad de la estructuración rubro por rubro (0--100) y (ii) calificación, también en escala 0--100, del \emph{score} de compatibilidad y de las explicaciones por aspecto, complementada con una comparación cualitativa de rankings. Esta decisión se alinea con recomendaciones de la literatura para escenarios con pocos ejemplos y con la necesidad de capturar matices que métricas agregadas estándar no siempre reflejan.


