\chapter{Marco Teórico}
\label{chap:marco-teorico}

Este capítulo presenta los fundamentos teóricos que sustentan el desarrollo del sistema de recomendación de hojas de vida. Se abordan conceptos de procesamiento de lenguaje natural, sistemas de recomendación, modelos de lenguaje y arquitecturas de software relevantes para la extracción, estructuración y comparación de información contenida en documentos de texto.

\section{Procesamiento de Lenguaje Natural}

El procesamiento de lenguaje natural (NLP) es una disciplina que combina lingüística, informática e inteligencia artificial para dotar a las máquinas de la capacidad de entender, interpretar y generar lenguaje humano \cite{jurafsky2023speech}. En el contexto de este trabajo, las técnicas de NLP son fundamentales para transformar documentos no estructurados (HVs en formato PDF) en representaciones estructuradas que permitan análisis automatizado.

\subsection{Extracción y Limpieza de Texto}

La extracción de texto es un proceso fundamental dentro del análisis automatizado de documentos, especialmente cuando se trabaja con archivos en formatos que no garantizan una estructura interna uniforme, como los documentos PDF. En términos generales, este proceso consiste en identificar y recuperar el contenido textual presente en un documento, independientemente de si proviene de texto digital embebido o de representaciones gráficas que requieren técnicas de reconocimiento óptico de caracteres (OCR). La diversidad en la forma en que los PDF almacenan la información implica que los métodos de extracción deben ser capaces de manejar distintos niveles de estructuración y fidelidad del contenido.

Posterior a la extracción, se realiza una etapa de limpieza y normalización del texto. Esta etapa busca transformar el contenido recuperado en una representación consistente y procesable, e incluye actividades como la normalización de caracteres, la corrección de artefactos comunes de digitalización o conversión, y la eliminación de elementos considerados ruido, tales como símbolos no textuales, fragmentaciones incorrectas de palabras o puntuación irrelevante. Estas operaciones son esenciales para garantizar que el texto final pueda ser utilizado de manera efectiva en posteriores tareas de análisis, modelado o procesamiento lingüístico.



En este trabajo, se utilizan técnicas de limpieza específicas para documentos en español, incluyendo normalización de tildes y manejo de caracteres especiales comunes en HVs.


\section{Modelos de Lenguaje y Extracción de Información}

\subsection{Modelos de Lenguaje Grandes (LLMs)}

Los modelos de lenguaje grandes son sistemas de aprendizaje profundo entrenados con grandes volúmenes de texto, capaces de aprender representaciones complejas del lenguaje y comprender su contexto y semántica. En este trabajo se emplea GPT-4o-mini, un modelo de la familia GPT (Generative Pre-trained Transformer) desarrollado por OpenAI y desplegado a través de Azure OpenAI Services. Estos modelos pueden generar respuestas estructuradas a partir de instrucciones bien definidas y adaptarse a distintos dominios o tareas con un ajuste mínimo.


\subsection{Prompt Engineering}

El \emph{prompt engineering} consiste en diseñar instrucciones que guían a los modelos de lenguaje para generar resultados precisos y estructurados. En tareas de extracción y organización de información, esta práctica permite definir con claridad el formato de salida y descomponer procesos complejos en pasos intermedios. Al incluir ejemplos dentro del propio prompt, el modelo puede adaptarse mejor al contexto y producir respuestas más consistentes. Para la orquestación de estas interacciones se emplea LangChain \cite{langchain}, un framework que permite gestionar plantillas de prompts, estructurar las respuestas mediante parsers, manejar errores y conectar distintos proveedores de modelos.

\section{Sistemas de Recomendación y Matching de Perfiles}

\subsection{Recomendación Basada en Contenido}

Los sistemas de recomendación basados en contenido filtran elementos (en este caso, candidatos) basándose en las características y preferencias del usuario (en este caso, requisitos del puesto). Los sistemas basados en contenido utilizan información intrínseca de los elementos a recomendar \cite{ricci2011introduction}.

El proceso  incluye:
\begin{enumerate}
  \item \textbf{Representación de perfiles}: Transformar información de candidatos y puestos en un diccionario de características.
  \item \textbf{Medida de similitud}: Calcular qué tan similar es un candidato a un puesto utilizando funciones de distancia o similitud.
  \item \textbf{Ranking}: Ordenar candidatos según su puntaje de compatibilidad.
\end{enumerate}

\subsection{Matching por Aspectos Múltiples}

En lugar de calcular una única medida de similitud, el matching por aspectos múltiples descompone la comparación en dimensiones independientes. Cada aspecto se evalúa por separado y luego se combinan los resultados mediante un esquema de ponderación.

En este trabajo, se evalúan ocho aspectos:
\begin{enumerate}
  \item \textbf{Experiencia}: Años y relevancia de experiencia laboral previa.
  \item \textbf{Habilidades técnicas}: Tecnologías, herramientas y competencias técnicas.
  \item \textbf{Educación}: Nivel educativo, títulos y instituciones.
  \item \textbf{Responsabilidades}: Match entre responsabilidades previas y requeridas.
  \item \textbf{Certificaciones}: Certificaciones profesionales relevantes.
  \item \textbf{Habilidades blandas}: Competencias interpersonales y de trabajo en equipo.
  \item \textbf{Idiomas}: Nivel de dominio de idiomas requeridos.
  \item \textbf{Ubicación}: Compatibilidad geográfica y modalidad de trabajo.
\end{enumerate}

Cada aspecto evaluado recibe un puntaje entre 0 y 1, donde un valor más alto representa una mayor compatibilidad. Un puntaje de 1.0 indica compatibilidad completa, valores entre 0.5 y 0.9 reflejan compatibilidad parcial, entre 0.0 y 0.4 indican baja compatibilidad, y un valor de -1.0 se asigna cuando no hay datos suficientes para realizar la evaluación.


\subsection{Sistema de Pesos Configurable}

El puntaje final se calcula como una suma ponderada:

\begin{equation}
\text{Score}_{final} = \sum_{i=1}^{n} w_i \cdot s_i
\end{equation}

donde $w_i$ es el peso del aspecto $i$, $s_i$ es el puntaje del aspecto $i$, y $\sum_{i=1}^{n} w_i = 1$.

Los pesos pueden configurarse según el tipo de puesto:
\begin{itemize}
  \item \textbf{Perfil Junior}: Mayor peso en educación y habilidades técnicas.
  \item \textbf{Perfil Senior}: Mayor peso en experiencia y certificaciones.
\end{itemize}

Si un aspecto tiene puntaje $-1.0$ (no evaluable), se excluye del cálculo y los pesos restantes se normalizan para que sumen 1.0.


\section{Arquitectura de Sistemas y Herramientas}

\subsection{Arquitectura en Capas}

El sistema implementa una arquitectura en capas que separa responsabilidades para facilitar la mantebilidad, robustez y testabilidad de la aplicación

\begin{enumerate}
  \item \textbf{Capa de Presentación (Frontend)}: Interfaz web desarrollada en React que permite a los usuarios interactuar con el sistema.
  \item \textbf{Capa de API}: Endpoints RESTful desarrollados con FastAPI que exponen la funcionalidad del sistema.
  \item \textbf{Capa de Servicios}: Lógica de negocio que orquesta el procesamiento de datos y análisis.
  \item \textbf{Capa de Repositorios}: Abstracción de acceso a datos que simplifica operaciones CRUD.
  \item \textbf{Capa de Persistencia}: Base de datos SQLite que almacena HVs, ofertas de trabajo y resultados de análisis.
\end{enumerate}



