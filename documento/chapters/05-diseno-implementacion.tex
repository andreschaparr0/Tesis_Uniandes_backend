\chapter{Diseño, Arquitectura e Implementación}
\label{chap:diseno-implementacion}

\section{Visión general del sistema}

La aplicación implementada permite que un profesional de recursos humanos cargue hojas de vida en PDF y descripciones de trabajo en texto, las estructure automáticamente mediante modelos de lenguaje y obtenga, en cuestión de segundos, un score de compatibilidad por candidato acompañado de un desglose explicativo por aspectos clave (experiencia, habilidades, educación, entre otros). Detrás de esta interacción sencilla se articula una arquitectura en capas que separa la interfaz de usuario, la lógica de negocio, el motor de recomendación y la persistencia de datos, lo que facilita la trazabilidad de cada decisión y la evolución independiente de los componentes.

Este capítulo describe cómo se materializó la metodología propuesta, desde el diseño de la arquitectura del sistema hasta los aspectos centrales de su implementación. Se parte de una vista global que muestra cómo el usuario interactúa con la aplicación, cómo el frontend se comunica con la API y cómo esta, a su vez, orquesta servicios, núcleo de recomendación y acceso a datos. A continuación se muestra la figura que resume esta arquitectura por capas y servirá como referencia visual a lo largo del capítulo.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{Arquitectura_aplicacion.png}
    \caption{Arquitectura de la aplicación}
    \label{fig:diagram-arquitectura}
\end{figure}

\subsection{Arquitectura general y flujo de usuario}

La arquitectura propuesta sigue un patrón cliente–servidor en el que el usuario de recursos humanos interactúa con un frontend web desarrollado en React. Este frontend consume una API REST construida con FastAPI, encargada de recibir las solicitudes (subir HVs, registrar descripciones de trabajo, lanzar análisis y consultar resultados) y delegar la lógica de negocio a una capa de servicios. Los servicios coordinan dos elementos principales del backend: por un lado, el \emph{core} del sistema, donde se ubican la limpieza de texto, la estructuración basada en modelos de lenguaje (LLM) y el motor de recomendación por aspectos; por otro lado, la capa de datos, compuesta por repositorios y una base de datos SQLite que almacena HVs, descripciones y análisis. De esta forma, el flujo típico es: usuario \(\rightarrow\) frontend \(\rightarrow\) API \(\rightarrow\) servicios \(\rightarrow\) core y datos, y de regreso hacia el usuario con un score final y explicaciones asociadas.

La Figura \ref{fig:diagram-arquitectura} se organiza en cuatro componentes principales. En primer lugar, el \textbf{frontend}, que ofrece la interfaz donde se cargan documentos y se consultan análisis. En el backend, se distinguen tres bloques: (i) la \textbf{capa de aplicación}, que agrupa API y servicios y define los flujos de casos de uso; (ii) la \textbf{capa de datos}, compuesta por repositorios y la base de datos responsable de la persistencia; y (iii) el \textbf{core} de la aplicación, donde residen el pipeline de NLP (limpieza y estructuración) y el motor de recomendación con sus comparadores por aspecto. Esta separación permite razonar sobre el sistema tanto desde la perspectiva de arquitectura de software como desde la perspectiva de flujo de información.

\subsection{Estructura del capítulo}

Para facilitar la lectura, el resto del capítulo se organiza siguiendo la descomposición que sugiere la arquitectura. Primero se presenta en detalle el backend por capas, comenzando por la API y los servicios, continuando con los repositorios y el modelo de datos, despues se profundiza en el core del sistema conectando estos elementos con las decisiones metodológicas descritas en el capítulo anterior. Finalmente, se describe el rol del frontend y su interacción con la API, resaltando cómo se materializa el flujo de usuario en la interfaz y cómo se presentan los resultados de manera que apoyen la toma de decisiones en el primer filtro de selección.

\section{Vista general del backend}

El backend del sistema implementa la lógica de negocio necesaria para transformar documentos en estructuras comparables, ejecutar el motor de recomendación y almacenar de forma persistente los resultados. Está organizado en capas bien definidas que separan el API y la logica de negocio (servicios), el núcleo de procesamiento (limpieza, estructuración y comparación) y el acceso a datos (repositorios y base de datos). Esta separación favorece la mantenibilidad y permite razonar sobre cada responsabilidad de forma aislada, al tiempo que facilita la reutilización de componentes en distintos flujos de la aplicación.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{Arquitectura_aplicacion_backend.png}
    \caption{Arquitectura por capas del backend}
    \label{fig:arquitectura_backend}
\end{figure}
Desde el punto de vista de la comunicación interna, la API recibe las solicitudes provenientes del frontend y delega en la capa de servicios tareas como procesar un nuevo CV, registrar una oferta o ejecutar un análisis. Los servicios, a su vez, invocan el core para limpiar y estructurar texto, o para calcular puntajes de compatibilidad, y utilizan los repositorios para leer y escribir en la base de datos SQLite. Como se aprecia en la Figura \ref{fig:arquitectura_backend}, las llamadas fluyen de API a servicios, de servicios al core, y de allí a los repositorios, cerrando el ciclo al devolver al usuario información enriquecida (scores, breakdowns y resúmenes) a través de la misma API.

\section{Capa de aplicación: API y servicios}

\subsection{Introducción a la capa de aplicación}
La capa de aplicación es el punto de entrada del backend: recibe las peticiones HTTP provenientes del frontend, las valida y las traduce en operaciones de negocio concretas. En ella se ubican la API, implementada con FastAPI, y la capa de servicios, responsable de coordinar el pipeline de limpieza, estructuración, recomendación y acceso a datos. De esta forma, la lógica de negocio queda encapsulada en servicios reutilizables, mientras que la API se limita a exponer endpoints bien definidos y a gestionar aspectos transversales como serialización, manejo de errores y documentación. En la siguiente Figura \ref{fig:capa_de_aplicacion_en_backend} se muestra cual es la capa de aplicación en el backend.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{Arquitectura_backend_capa_de_aplicacion.png}
    \caption{Capa de aplicación en el backend}
    \label{fig:capa_de_aplicacion_en_backend}
\end{figure}


En términos de flujo, como se puede observar en la siguiente Figura \ref{fig:Capa_de_aplicacion} , el frontend invoca los endpoints de la API para manejar todo lo referente a las HV, descripciones o análisis; la API delega exclusivamente en el servicio correspondiente (CVService, JobService, RecommendationService o AnalysisService), el cual encapsula toda la lógica de orquestación. Es el servicio quien invoca al core para el procesamiento y quien interactúa con los repositorios para la persistencia de datos. Las figuras de secuencia incluidas en el apéndice de figuras (Figuras \ref{fig:seq-subir-cv}, \ref{fig:seq-crear-job} y \ref{fig:seq-analizar}) ilustran estos flujos paso a paso para los casos de uso principales.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{Capa_de_aplicacion.png}
    \caption{Arquitectura de la capa de aplicación}
    \label{fig:Capa_de_aplicacion}
\end{figure}
\subsection{API REST: endpoints y tecnologías}

La API se implementó utilizando FastAPI sobre Python 3.11, aprovechando su soporte para tipado estático y generación automática de documentación. El servidor de desarrollo se levanta con Uvicorn, exponiendo la aplicación en local, mientras que la configuración de CORS permite el acceso controlado desde el cliente web. Adicionalmente, la documentación interactiva detallada de todos los endpoints, incluyendo esquemas de entrada y salida, se genera automáticamente y puede consultarse en tiempo real accediendo a la ruta \texttt{/docs} del servidor (por defecto \texttt{http://localhost:8000/docs}).

Para estructurar la comunicación, los endpoints se agrupan por recurso funcional como se ilustra en la Figura \ref{fig:Figura_API}. Esta organización facilita la mantenibilidad y permite que cada controlador se especialice en un tipo de entidad. A continuación, se describen los grupos principales de endpoints mostrados en el diagrama, cuyo detalle técnico completo (parámetros y respuestas) se encuentra documentado en el Apéndice \ref{app:api-docs}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{Figura_API.png}
    \caption{Diseño de la API}
    \label{fig:Figura_API}
\end{figure}

\subsubsection*{Gestión de Hojas de Vida (CVs)}
El componente \texttt{CV\_Endpoint} agrupa las operaciones para la administración del ciclo de vida de las hojas de vida. Su función principal es la carga de documentos (\texttt{crear\_cv}), donde el sistema recibe un archivo PDF, extrae su contenido y lo procesa. Adicionalmente, expone métodos para listar todos los candidatos (\texttt{listar\_cvs}), consultar el detalle de uno específico (\texttt{obtener\_cv}), buscar por nombre (\texttt{buscar\_cvs}) y eliminar registros (\texttt{eliminar\_cv}). Puede consultar el detalle técnico de estos endpoints en el Apéndice \ref{sec:api-hvs}.

\subsubsection*{Gestión de Descripciones de Trabajo (Jobs)}
El componente \texttt{Job\_Endpoint} gestiona las ofertas laborales de manera análoga. Permite registrar nuevas descripciones mediante texto plano (\texttt{crear\_job}), las cuales son procesadas para estructurar requisitos. Las operaciones de consulta (\texttt{listar\_jobs}, \texttt{obtener\_job}, \texttt{buscar\_jobs}) facilitan la recuperación de información, mientras que \texttt{eliminar\_job} permite la gestión del ciclo de vida de la vacante. Puede consultar el detalle técnico de estos endpoints en el Apéndice \ref{sec:api-jobs}.

\subsubsection*{Análisis y Estadísticas}
El componente \texttt{Analysis\_Endpoint} actúa como el núcleo funcional donde converge la información. Su método principal, \texttt{analizar}, desencadena la comparación entre una HV y un Job. Este módulo también ofrece endpoints para consultar el historial (\texttt{listar\_analyses}), obtener detalles específicos (\texttt{obtener\_analysis}), generar rankings de mejores candidatos (\texttt{analyses\_por\_job} o top candidatos) y visualizar métricas generales del sistema (\texttt{estadisticas}). Puede consultar el detalle técnico de estos endpoints en el Apéndice \ref{sec:api-analysis}.

Cada endpoint está diseñado bajo el patrón de \emph{application services}, delegando la totalidad del procesamiento y la persistencia a la capa de servicios. Su responsabilidad se limita a validar la estructura de la petición HTTP, invocar el método de servicio adecuado y transformar la respuesta de negocio en una respuesta HTTP con los códigos de estado estándar.

\subsection{Servicios y lógica de negocio}

La capa de servicios sigue un patrón de \emph{application services} que centraliza la lógica de negocio, orquestando la interacción entre los componentes del sistema. Como se ilustra en la Figura \ref{fig:FiguraServices}, estos servicios actúan como intermediarios que coordinan el acceso a datos y la ejecución de procesos del núcleo, garantizando que la API permanezca desacoplada de la implementación subyacente.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{Figura_Services.png}
    \caption{Componentes de la capa de servicios}
    \label{fig:FiguraServices}
\end{figure}

El backend se estructura en cuatro servicios principales, cada uno con responsabilidades delimitadas:

\begin{itemize}
  \item \textbf{CVService}: Gestiona el ciclo de vida de las hojas de vida. Sus funciones principales incluyen procesar archivos PDF (\texttt{process\_cv\_from\_file}) interactuando con el nucleo y administrar la persistencia de datos (creación, búsqueda y eliminación) interactuando directamente con la capa de repositorios.
  
  \item \textbf{JobService}: Centraliza la lógica relacionada con las descripciones de trabajo. Coordina la estructuración de texto plano mediante IA (\texttt{process\_job\_from\_text}) interactuando con el core y gestiona todas las operaciones CRUD sobre las ofertas laborales, asegurando que los datos almacenados cumplan con el esquema requerido.

  \item \textbf{AnalysisService}: Administra el historial y consulta de resultados. Este servicio se encarga de persistir los análisis generados, recuperar detalles específicos, y ofrecer consultas agregadas como rankings de candidatos  o estadísticas globales del sistema, sirviendo como fuente de verdad para la visualización de datos.

  \item \textbf{RecommendationService}: Encapsula la inteligencia del sistema. Su método principal (\texttt{analyze}) orquesta el motor de recomendación (\texttt{RecommendationEngine}) para comparar los datos estructurados de una HV y un Job. Este servicio es responsable de calcular los puntajes de compatibilidad y generar los desgloses explicativos, delegando la persistencia del resultado final al \texttt{AnalysisService}.
\end{itemize}

Este diseño modular facilita la mantenibilidad y las pruebas unitarias, ya que cada servicio puede aislarse para verificar su lógica de orquestación independientemente de la interfaz HTTP o de la base de datos.
\section{Capa de Datos y Persistencia}
\label{sec:capa-datos}

\subsection{Introducción a la capa de datos}
Esta sección detalla la capa encargada de garantizar la persistencia y consistencia de la información dentro del sistema. Como se aprecia en la Figura \ref{fig:capa_de_datos_en_backend}, donde se resalta en amarillo el componente de datos, esta capa fundamenta el almacenamiento del sistema. La arquitectura se basa en el patrón \textit{Repository}, el cual actúa como una colección en memoria para objetos del dominio, abstrayendo los detalles de implementación de la base de datos subyacente. En este caso, se emplea SQLite como motor de almacenamiento debido a su ligereza y suficiencia para el alcance del prototipo, gestionado a través de \texttt{SQLAlchemy} como ORM (Object-Relational Mapper). Esta combinación permite manipular los datos utilizando clases y objetos de Python, facilitando la evolución del esquema sin atar la lógica de negocio a consultas SQL específicas.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{Arquitectura_backend_capa_de_datos.png}
    \caption{Capa de datos en el backend}
    \label{fig:capa_de_datos_en_backend}
\end{figure}

\subsection{Implementación de Repositorios y Flujo de Persistencia}
\subsection{Modelo de Datos e Implementación de Persistencia}

El diseño de la capa de datos se fundamenta en un modelo relacional simple pero robusto, representado en la Figura \ref{fig:er-modelo}, que permite almacenar de forma estructurada la información clave del proceso de selección. El esquema consta de tres entidades principales: \textbf{CVS}, que almacena los perfiles de los candidatos; \textbf{JOBS}, que contiene las descripciones de las vacantes; y \textbf{ANALYSES}, una tabla intermedia que materializa la relación muchos a muchos entre candidatos y vacantes, registrando los resultados detallados de cada evaluación de compatibilidad.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{ModeloEntidadRelacion.png}
    \caption{Modelo de datos (ER)}
    \label{fig:er-modelo}
\end{figure}

Para llevar este modelo a la implementación, se emplea un diseño que desacopla la definición de las entidades de su lógica de manipulación, tal como se introdujo en la Figura \ref{fig:capa_de_datos_en_backend}. Como se detalla en el Apéndice (Figura \ref{fig:DetallesImplementacionDatos}), se utilizan clases de modelo (\textit{Models}) que heredan de la base declarativa de SQLAlchemy para mapear los atributos definidos en el diagrama ER a columnas físicas de la base de datos SQLite.

La manipulación de estos datos se delega a los repositorios, que actúan como gestores de transacciones. El flujo de persistencia, ilustrado en la Figura \ref{fig:flujo_persistencia_analysis}, sigue una secuencia rigurosa para asegurar la integridad referencial: cuando un servicio solicita guardar un análisis, el repositorio transforma los datos en una instancia del modelo ORM, gestiona la sesión de la base de datos y ejecuta la confirmación (\textit{commit}), retornando finalmente el objeto con su identificador persistido para su uso en las capas superiores.

\section{Core del sistema}
\subsection{Introducción al core de la aplicación}
El \textit{Core} del sistema representa el componente central donde reside la inteligencia de la aplicación, separado lógica y funcionalmente de las capas de servicio y persistencia. Como se aprecia en la Figura \ref{fig:arquitectura_backe_core}, este núcleo agrupa los módulos de procesamiento intensivo en dos grandes motores: el motor de estructuración, encargado de interpretar y estandarizar la información no estructurada de documentos y textos; y el motor de recomendación, que orquesta los algoritmos de comparación para evaluar la compatibilidad entre candidatos y vacantes. Esta disposición permite que el procesamiento cognitivo y el cálculo de similitudes evolucionen de forma independiente a la lógica de control de la API.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{Arquitectura_backend_core.png}
    \caption{Core de la aplicación en el backend}
    \label{fig:arquitectura_backe_core}
\end{figure}

\section{Motor de Estructuración }

El componente de estructuración es responsable de transformar documentos no estructurados —como hojas de vida en formato PDF y descripciones de trabajo en texto libre— en objetos de datos estandarizados (JSON) que el sistema pueda procesar algorítmicamente. Este módulo actúa como puente entre la entrada de usuario y el motor de recomendación, garantizando que la información heterogénea sea normalizada bajo un esquema común.

\subsection{Arquitectura del componente de estructuración}

Como se ilustra en la Figura \ref{fig:arquitectura_estructuracion}, el flujo de información comienza en la capa de servicios, donde `CVService` y `JobService` actúan como orquestadores. Dependiendo del tipo de entrada, la solicitud se enruta hacia uno de los dos pipelines especializados: el `Pipeline HV` para el procesamiento de documentos PDF, o el `Pipeline Descripción` para textos de ofertas laborales. Ambos pipelines convergen en el módulo central de estructuración, que encapsula la lógica de interacción con los modelos de lenguaje.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{DiagramaEstructuraciones.png}
    \caption{Arquitectura del componente de estructuración}
    \label{fig:arquitectura_estructuracion}
\end{figure}

El diseño desacopla la recepción del archivo de su procesamiento cognitivo. Mientras que los servicios gestionan la carga y persistencia preliminar, el núcleo de estructuración se encarga exclusivamente de la extracción de entidades, validación de esquemas y limpieza de datos. Esto permite que, aunque las fuentes de datos sean distintas (.pdf vs .txt), el resultado final sea siempre una estructura coherente y lista para ser consumida por los algoritmos de comparación.

\section{Pipeline de procesamiento de hojas de vida}

\label{subsec:pipeline-hv}

El procesamiento de hojas de vida constituye uno de los flujos críticos del sistema, dado que transforma documentos PDF no estructurados en datos procesables. Como se detalla en la Figura \ref{fig:pipeline_hv}, este proceso se orquesta secuencialmente a través de tres fases principales: extracción, estructuración cognitiva y validación.

\begin{samepage}
\noindent
\begin{minipage}[t]{0.62\textwidth}
\vspace{0pt}
\indent El flujo inicia con la recepción del archivo PDF, el cual ingresa a la \textbf{Fase 1: Extracción y Limpieza}. En esta etapa, se utiliza la librería PyMuPDF para extraer el contenido textual crudo, el cual es sometido inmediatamente a un proceso de normalización (detallado en la Sección \ref{subsec:fase-limpieza}) para eliminar ruido y caracteres no deseados, resultando en un texto limpio apto para el procesamiento.

\medskip

\indent Posteriormente, en la \textbf{Fase 2: Estructuración de Elementos}, el sistema emplea una estrategia iterativa de segmentación semántica. En lugar de procesar el documento en un único paso, se construyen prompts específicos para cada sección clave (información personal, experiencia, educación, entre otros) y se invocan modelos de lenguaje (GPT-4o-mini) para extraer cada componente por separado. Esta estrategia, que profundizaremos en la Sección \ref{subsec:fase-estructuracion-ia}, maximiza la precisión de la extracción al reducir la ventana de contexto necesaria para cada consulta.

\medskip

\indent Finalmente, la \textbf{Fase 3: Consolidación y Validación} se encarga de ensamblar las respuestas parciales. Las salidas del modelo son depuradas de marcas de formato (markdown), unificadas en un único objeto JSON y sometidas a una validación estricta de esquema para garantizar la integridad de los datos, proceso que se describe en la Sección \ref{subsec:fase-validacion}. El resultado es un JSON estructurado final, listo para ser almacenado y utilizado por el motor de recomendación.
\end{minipage}%
\hfill
\begin{minipage}[t]{0.35\textwidth}
    \vspace{0pt}
    \centering
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.95\textwidth, height=0.65\textheight, keepaspectratio]{Pipeline_Estructuracion_CV.png}
        \caption{Pipeline de estructuración de hojas de vida}
        \label{fig:pipeline_hv}
    \end{figure}
\end{minipage}
\end{samepage}
\subsection{Fase 1: Extracción y limpieza de texto}
\label{subsec:fase-limpieza}

La primera fase del pipeline tiene como objetivo transformar el archivo PDF binario en una cadena de texto normalizada, libre de ruido que pueda interferir con el procesamiento del modelo de lenguaje. Como se observa en la Figura \ref{fig:limpieza_cv}, este proceso se divide en dos etapas: la extracción inicial mediante herramientas de bajo nivel y un pipeline de limpieza sintáctica.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{Fase_Limpieza_Pipeline_CV.png}
    \caption{Proceso de limpieza y normalización de texto}
    \label{fig:limpieza_cv}
\end{figure}

Inicialmente, el sistema utiliza \textit{PyMuPDF} para extraer el contenido textual de todas las páginas del documento, concatenándolas en una única cadena de ("Texto Crudo") como se ve en la figura \ref{. Este texto suele contener irregularidades derivadas del formato PDF, como saltos de línea arbitrarios, caracteres de control o problemas de codificación. Para mitigar esto, el texto pasa por una serie de funciones de limpieza secuenciales implementadas en el módulo `limpieza.py`:

\begin{enumerate}
    \item \textbf{Normalización de caracteres (Quitar Tildes):} Se convierten caracteres acentuados a sus equivalentes ASCII (ej: 'á' $\rightarrow$ 'a') para estandarizar la entrada, reduciendo la variabilidad léxica sin perder el significado semántico esencial.
    \item \textbf{Filtrado de ruido (Quitar Símbolos Raros):} Se eliminan caracteres no alfanuméricos o símbolos de formato problemáticos (como §, ï, o bullets personalizados) que suelen aparecer al extraer texto de documentos con diseño complejo.
    \item \textbf{Reconstrucción léxica (Unir Letras Separadas):} Se aplica una heurística basada en expresiones regulares para detectar y corregir palabras que aparecen con espaciado inter-carácter (ej: "T I T U L O" $\rightarrow$ "TITULO"), un artefacto común en encabezados de hojas de vida.
    \item \textbf{Limpieza final:} Se eliminan caracteres especiales restantes y puntuación excesiva, y se convierte todo el texto a minúsculas para garantizar consistencia en el procesamiento posterior.
\end{enumerate}

A modo de ilustración, el siguiente ejemplo muestra la transformación que sufre un fragmento de texto típico tras pasar por este pipeline:

\begin{quotation}
    \small
    \noindent \textbf{Entrada (Texto Crudo):} "D E S A R R O L L A D O R -- FULL STACK. ¡Experiencia en: Python, SQL & Java! (2023)." \\
    \noindent \textbf{Salida (Texto Limpio):} "desarrollador full stack experiencia en python sql java 2023"
\end{quotation}

El resultado ("Texto Limpio") en la Figura \ref{fig:limpieza_cv} es una representación simplificada y uniforme del contenido del CV, optimizada para ser tokenizada eficientemente por el modelo de IA en la siguiente fase.

\subsection{Fase 2: Estrategia de prompting y estructuración}
\label{subsec:fase-estructuracion-ia}

Una vez obtenido el texto limpio, el sistema inicia la fase de estructuración cognitiva. A diferencia de enfoques tradicionales que intentan extraer toda la información en una sola consulta (lo cual suele saturar la ventana de contexto del modelo y generar alucinaciones), esta implementación utiliza una estrategia secuencial y modular basada en la segmentación por tópicos.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.35\linewidth]{Fase_Estructuracion_Pipeline_CV.png}
    \caption{Proceso iterativo de estructuración con LLMs}
    \label{fig:estructuracion_iterativa}
\end{figure}

Como se ilustra en la Figura \ref{fig:estructuracion_iterativa}, el texto completo del CV se inyecta repetidamente en un ciclo de consultas, donde en cada iteración se utiliza un \textit{prompt} específico diseñado para extraer una única categoría de información (Información Personal, Educación, Experiencia, Habilidades, etc.). Esta metodología combina tres estrategias de \textit{Prompt Engineering} definidas en el marco teórico:

\begin{itemize}
    \item \textbf{Role Prompting:} Se instruye al modelo explícitamente: \textit{``Eres un experto en extraer información estructurada de hojas de vida''}. Esta técnica, identificada como el patrón de Persona \cite{promptguide2024}, condiciona la atención del modelo a entidades y terminología relevantes del dominio de reclutamiento.
    \item \textbf{Structured Output Prompting:} Se define un esquema JSON rígido dentro del prompt y se prohíbe la generación de texto conversacional adicional. Esta restricción es fundamental para garantizar la interoperabilidad con el sistema backend \cite{promptguide2024}.
    \item \textbf{Zero-Shot Prompting:} No se proveen ejemplos de CVs previos en el contexto; el modelo opera basándose únicamente en las instrucciones semánticas y el esquema objetivo, aprovechando su capacidad de generalización pre-entrenada \cite{promptguide2024}.
\end{itemize}

A continuación se presenta un ejemplo de la estructura de prompt utilizada para la extracción de información personal:

\begin{quotation}
    \small
        \noindent \textbf{System Message:} ``Eres un experto en extraer información estructurada de hojas de vida. IMPORTANTE: Responde ÚNICAMENTE con la estructura que se te pide, sin texto adicional.'' \\
        \noindent \textbf{User Message:} ``Extrae únicamente la información personal básica del siguiente CV. Responde en formato JSON con esta estructura exacta:'' 


    \begin{verbatim}
    {
        "name": "nombre completo",
        "email": "correo electrónico",
        "phone": "número de teléfono",
        "location": "ubicación/ciudad"
    }
    \end{verbatim}
    Si no encuentras alguna información, deja el campo como DESCONOCIDO"
\end{quotation}

Este enfoque granular permite validar y corregir cada sección de forma independiente (ver Apéndice \ref{tab:prompts-cv} para el listado completo de prompts utilizados). Si el modelo falla al extraer la experiencia, no afecta la extracción de la educación, lo que aumenta significativamente la robustez del sistema frente a documentos con formatos atípicos.
\subsection{Fase 3: Consolidación y validación de datos}
\label{subsec:fase-validacion}

La etapa final del pipeline asegura que la información generada por el modelo sea sintácticamente válida y estructuralmente coherente antes de ser almacenada. Como se muestra en la Figura \ref{fig:validacion_json}, este proceso aborda uno de los desafíos más comunes al trabajar con LLMs: la inestabilidad en el formato de salida.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.35\linewidth]{Fase_Validacion_Pipeline_Descripcion.png}
    \caption{Flujo de consolidación y validación de datos}
    \label{fig:validacion_json}
\end{figure}

El flujo implementado ejecuta las siguientes operaciones:

\begin{enumerate}
    \item \textbf{Limpieza de Markdown:} Los modelos de chat tienden a envolver el código en bloques de formato (ej: ```json ... ```). El sistema detecta y elimina estos delimitadores para extraer el objeto JSON puro.
    \item \textbf{Parsing Seguro:} Se utiliza un decodificador JSON robusto que captura errores de sintaxis. Si el modelo genera un JSON malformado, el sistema captura la excepción y retorna una estructura vacía por defecto en lugar de romper la ejecución del servicio.
    \item \textbf{Unificación de Fragmentos:} Los objetos JSON parciales obtenidos en la Fase 2 (uno por cada sección: personal, educación, etc.) se fusionan en un único diccionario maestro que guarda la informacion de todos los elementos.
    \item \textbf{Validación de Schema (Inyección de Defaults):} Se verifica que todas las claves obligatorias existan. Si el modelo omitió algún campo (por ejemplo, no encontró certificaciones), el sistema inyecta automáticamente un valor por defecto (lista vacía o cadena vacía), garantizando que el objeto final cumpla estrictamente con la estructura esperada por el motor de recomendación.
\subsection{Pipeline de procesamiento de descripciones de trabajo}
\label{subsec:pipeline-jobs}



\begin{samepage}
\noindent
\begin{minipage}[t]{0.62\textwidth}
\vspace{0pt}
\indent De manera análoga al procesamiento de CVs, el sistema implementa un flujo especializado para transformar las descripciones de vacantes en estructuras de datos normalizadas. Como se observa en la Figura \ref{fig:pipeline_job}, este pipeline comparte la arquitectura secuencial de tres fases, adaptando sus componentes internos a la naturaleza textual y semántica de las ofertas laborales.
\medskip

\indent El proceso comienza con la recepción del texto de la oferta laboral. En la \textbf{Fase 1}, se realiza una limpieza preliminar similar a la descrita anteriormente, aunque simplificada, dado que la entrada suele ser texto plano en lugar de un documento binario complejo.

\medskip

\indent La \textbf{Fase 2} constituye el núcleo diferencial de este pipeline. Aquí, la estrategia de segmentación se ajusta para identificar secciones propias de una vacante, como responsabilidades, beneficios y información basica. Además, se incorporan capacidades de inferencia deductiva (p.ej., deducir habilidades blandas a partir de las funciones del cargo), un aspecto que se detallará en la Sección \ref{subsec:fase-estructuracion-job}.

\medskip

\indent Finalmente, la \textbf{Fase 3} replica el mecanismo de consolidación y validación, asegurando que el objeto JSON resultante cumpla con el esquema requerido para la comparación bidireccional con los candidatos.
\end{minipage}%
\hfill
\begin{minipage}[t]{0.22\textwidth}
    \vspace{0pt}
    \centering
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.95\textwidth, height=0.65\textheight, keepaspectratio]{Pipeline_Estructuracion_Descripcion.png}
        \caption{Pipeline de estructuración de descripciones de trabajo}
        \label{fig:pipeline_job}
    \end{figure}
\end{minipage}
\end{samepage}

\subsubsection{Fase 1: Limpieza y normalización}
Aunque la entrada es texto plano y no requiere extracción óptica o binaria compleja (como PyMuPDF), se aplica el mismo módulo de limpieza sintáctica descrito en la Sección \ref{subsec:fase-limpieza}. Esto garantiza que caracteres especiales, problemas de codificación o espaciados irregulares sean corregidos antes de invocar al modelo de lenguaje, manteniendo la consistencia en la calidad de los datos de entrada.

\subsubsection{Fase 2: Estrategia de prompting y estructuración}
\label{subsec:fase-estructuracion-job}

En esta fase se materializa la inteligencia del sistema para comprender los requisitos de una vacante. Siguiendo el patrón de segmentación semántica utilizado en el pipeline de CVs, el texto de la descripción se procesa iterativamente utilizando prompts especializados para extraer componentes como información básica, responsabilidades, educación y beneficios (Figura \ref{fig:estructuracion_job}).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.35\linewidth]{Fase_Estructuracion_Pipeline_Descripcion.png}
    \caption{Estrategia de estructuración de ofertas laborales}
    \label{fig:estructuracion_job}
\end{figure}

Sin embargo, este pipeline introduce dos capacidades cognitivas adicionales que lo diferencian de la extracción literal:

\begin{itemize}
    \item \textbf{Deducción de Habilidades Blandas (ver Figura \ref{fig:Flujo_Inferir_Habilidades_Blandas}):} A menudo, las ofertas laborales no listan explícitamente las habilidades blandas requeridas, pero estas se encuentran implícitas en las responsabilidades (p.\,ej., ``liderar equipos ágiles'' implica ``liderazgo'' y ``comunicación''). El sistema primero intenta extraer habilidades blandas explícitas mediante el prompt correspondiente. En caso de que no se encuentren, se activa automáticamente un mecanismo de inferencia que analiza semánticamente las funciones del cargo mediante las responsabilidades extraías por el LLM y deduce las 3-5 habilidades blandas más críticas, enriqueciendo el perfil de la vacante más allá del texto literal. Este flujo se puede observar en el diagrama de flujos mostrado en el indice en la Figura \ref{fig:Flujo_Inferir_Habilidades_Blandas}.
    
    \item \textbf{Detección de Idioma Contextual (ver Figura \ref{fig:Flujo_Inferir_Lenguaje}):} El sistema prioriza la extracción de requisitos de idioma explícitos mediante el prompt de idiomas estándar. Sin embargo, si la oferta no especifica idiomas (retorna lista vacía), se activa un mecanismo de recuperación que emplea un prompt de clasificación zero-shot para identificar el idioma en el que está redactado el texto completo de la oferta. Si se detecta, por ejemplo, que la oferta está en inglés, el sistema infiere automáticamente un requisito de ``Inglés - Nivel Intermedio'', asegurando que el motor de recomendación filtre candidatos aptos lingüísticamente incluso ante descripciones incompletas. Este flujo se puede observar en el diagrama de flujos mostrado en el indice en la Figura \ref{fig:Flujo_Inferir_Lenguaje}.
\end{itemize}

Estas estrategias transforman el proceso de una simple extracción de texto a una comprensión semántica de la necesidad del empleador, generando un perfil de vacante más robusto para el emparejamiento posterior. Los prompts específicos utilizados para estas inferencias se detallan en el Apéndice \ref{tab:prompts-job}, filas ``Inferencia soft skills'' y ``Detección de idioma''.

\subsubsection{Fase 3: Consolidación y validación}
Esta fase es funcionalmente idéntica a la descrita en la Sección \ref{subsec:fase-validacion}. Se ejecutan los mismos procesos de limpieza de markdown, unificación de fragmentos JSON y validación de esquema con inyección de valores por defecto. La única diferencia radica en el esquema objetivo, que en este caso corresponde a la estructura de una oferta laboral (incluyendo campos como rango salarial, modalidad de trabajo y beneficios).


\section{Motor de Comparaciones e Inteligencia de Matching}
\label{sec:motor-comparaciones}

Una vez que tanto las hojas de vida como las ofertas laborales han sido estructuradas en formato JSON, el sistema debe ejecutar la evaluación de compatibilidad entre candidatos y vacantes. Este proceso es orquestado por el \textbf{Motor de Comparaciones}, un componente del core que integra ocho algoritmos especializados de evaluación, cada uno diseñado para analizar una dimensión específica del ajuste candidato-puesto.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{Diagrama_Comparaciones.png}
    \caption{Arquitectura del Motor de Comparaciones}
    \label{fig:Diagrama_Comparaciones}
\end{figure}

Como se observa en la Figura \ref{fig:Diagrama_Comparaciones}, el motor recibe como entrada los documentos estructurados (archivos \texttt{.txt} para ofertas de trabajo y \texttt{.pdf} para CVs, previamente procesados por el motor de estructuración) y los canaliza hacia el módulo \texttt{Comparador Main}, implementado en. Este orquestador secuencial invoca a cada uno de los comparadores especializados, que a su vez emplean Azure OpenAI (GPT-4o-mini) para realizar evaluaciones semánticas de alto nivel. Las siguientes subsecciones detallan el pipeline de comparación y la arquitectura de los comparadores individuales.

\subsection{Pipeline de Comparación y Scoring}
\label{subsec:pipeline-comparacion}

\begin{samepage}
\noindent
\begin{minipage}[t]{0.60\textwidth}
\vspace{0pt}
\indent El proceso de evaluación de compatibilidad se ejecuta en tres etapas secuenciales que transforman dos documentos JSON estructurados en un análisis multidimensional con justificación explícita. 

\medskip

\indent El flujo inicia en la \textbf{Fase 1: Carga y Validación}, donde se recibe las rutas de los dos archivos JSON estructurados (CV y Job) generados por los pipelines de estructuración. El sistema carga ambos documentos mediante el método que incluye manejo robusto de excepciones para detectar JSON malformados o archivos faltantes. 

\medskip

\indent Posteriormente, en la \textbf{Fase 2: Comparación de Elementos}, se ejecuta el núcleo del motor de matching. El orquestador invoca secuencialmente ocho comparadores especializados, cada uno diseñado para evaluar un elemento: Experiencia, Habilidades Técnicas, Habilidades Blandas, Educación, Certificaciones, Lenguaje, Ubicación y Responsabilidades. Este procesamiento iterativo genera un diccionario de resultados que mapea cada aspecto evaluado a su score y razón correspondiente, detalle que se profundizará en subsecciones posteriores.

\medskip

\indent Finalmente, la \textbf{Fase 3: Agregación y Scoring} consolida los resultados individuales en un análisis unificado. Se aplica un algoritmo de ponderación configurable que asigna pesos específicos a cada dimensión evaluada elemento. El sistema maneja los casos donde no hay datos disponibles y normalización para el score final. El resultado final es un objeto JSON completo que incluye el score final ponderado, el desglose detallado por aspecto, el resumen narrativo y los aspectos ignorados, información que se almacena en la base de datos SQLite para consultas futuras.
\end{minipage}%
\hfill
\begin{minipage}[t]{0.35\textwidth}
    \vspace{0pt}
    \centering
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.95\textwidth, height=0.80\textheight, keepaspectratio]{Pipeline_Comparacion.png}
        \caption{Pipeline del motor de comparaciones}
        \label{fig:pipeline-comparacion}
    \end{figure}
\end{minipage}
\end{samepage}

\subsubsection{Fase 1: Carga y validación de datos estructurados}
\label{subsubsec:fase1-comparacion}

Antes de iniciar cualquier evaluación de compatibilidad, el sistema debe garantizar que los datos de entrada sean válidos y estén disponibles en el formato correcto. Esta fase, ilustrada en la Figura \ref{fig:fase1-carga-comparacion}, implementa un mecanismo de validación defensiva que previene errores en etapas posteriores del pipeline.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\linewidth]{Fase_Carga_Pipeline_Comparacion.png}
    \caption{Proceso de carga y validación de documentos estructurados}
    \label{fig:fase1-carga-comparacion}
\end{figure}

La imagen muestra la primera fase del proceso, que consiste en cargar los datos y validar que los archivos JSON estén en buen estado antes de continuar. Primero se leen los dos archivos necesarios (el CV y la descripción del trabajo), luego se revisa que su contenido sea correcto y tenga la estructura mínima esperada. Cuando ambas verificaciones se superan, se consideran como JSON’s válidos. Esta fase funciona como un filtro inicial que asegura que el sistema solo trabaje con información limpia y confiable.

\subsubsection{Fase 2: Comparación semántica por aspectos}
\label{subsubsec:fase2-comparacion}

\noindent En la segunda fase del pipeline, representada de forma general en la Figura \ref{fig:fase2-comparacion-general}, el sistema toma los JSON ya validados del CV y de la descripción de trabajo y los recorre aspecto por aspecto (experiencia, habilidades técnicas y blandas, educación, certificaciones, idiomas, ubicación y responsabilidades). Para cada uno de estos elementos se construye un prompt de comparación que resume la información relevante y la envía al modelo GPT-4o-mini, el cual devuelve un score de compatibilidad y una breve justificación en formato estructurado. De esta manera, la imagen sintetiza cómo un mismo esquema de prompt se reutiliza iterativamente sobre los distintos componentes del perfil para producir evaluaciones consistentes y comparables entre sí.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.35\linewidth]{Fase_Comparacion_General_Pipeline_comparacion.png}
    \caption{Vista general de la comparación de elementos por aspecto}
    \label{fig:fase2-comparacion-general}
\end{figure}

\noindent La Figura \ref{fig:fase2-comparacion} descompone esta fase mostrando cómo se emparejan los campos estructurados de la hoja de vida con los de la descripción de trabajo y qué peso por defecto aporta cada aspecto al cálculo global. Cada fila representa un comparador independiente (educación, experiencia, habilidades blandas y técnicas, certificaciones, idiomas, ubicación y beneficios/responsabilidades), todos ellos alimentados por el mismo esquema general de prompt y evaluados posteriormente con una ponderación específica.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\linewidth]{Fase_Comparacion_Pipeline_comparacion.png}
    \caption{Emparejamiento de elementos y pesos por defecto en la Fase 2}
    \label{fig:fase2-comparacion}
\end{figure}

Sobre esta base, la implementación reutiliza las mismas estrategias de \textit{Prompt Engineering} descritas en la Sección \ref{subsec:fase-estructuracion-ia} (rol, salida estructurada y enfoque zero-shot), pero ahora orientadas a la comparación entre dos objetos ya estructurados. Para cada fila de la Figura \ref{fig:fase2-comparacion}, el sistema construye un texto resumen a partir del JSON del CV y del Job (por ejemplo, las listas de habilidades, la experiencia o las certificaciones) y lo inyecta en un prompt especializado documentado en la Tabla \ref{tab:prompts-comp}. El modelo devuelve siempre un JSON con al menos un campo \texttt{score} en el rango \([0,1]\) (y, en algunos casos, banderas adicionales como \texttt{compatible}) y un campo \texttt{reason} con la justificación en lenguaje natural.

Como ejemplo ilustrativo y conciso, el comparador de \textbf{idiomas} construye un prompt que verifica si el nivel reportado en el CV cumple o supera el requerido en la oferta. Simplificado, su estructura es la siguiente:

\begin{quotation}
    \small
    \noindent \textbf{System Message:} ``Eres un experto en evaluar compatibilidad de niveles de idioma. Responde ÚNICAMENTE con JSON válido que contenga: 'compatible' (boolean), 'score' (0-1), 'reason' (string).'' \\
    \noindent \textbf{User Message:} ``Compara estos niveles de idioma y determina si el nivel del CV cumple con el requerido: \par CV: \textless nivel\_cv\textgreater \par Requerido: \textless nivel\_requerido\textgreater \par Si el CV cumple o supera el requerido, el \texttt{score} debe ser 1.0; si no cumple, el \texttt{score} debe ser 0.0. Responde en formato JSON.'' 
\end{quotation}

Este patrón se replica para el resto de comparadores, adaptando únicamente el contenido del texto de entrada (experiencia, habilidades técnicas, habilidades blandas, certificaciones, ubicación, etc.), mientras que la estructura general del prompt y de la salida permanece uniforme en todo el motor de comparaciones.

\subsubsection{Casos excepcionales en la comparación}

En la Figura \ref{fig:fase2-comparacion} se puede observar dos casos especiales donde el sistema aplica reglas adicionales para no perder señales relevantes que son los dos casos donde hay dos lineas conectandose en vez de una.

En \textbf{certificaciones}, cuando la descripción de trabajo no declara certificaciones obligatorias pero sí define habilidades técnicas, se activa una lógica: si el CV tampoco tiene certificaciones o el Job no tiene habilidades técnicas, el aspecto se marca como ignorado; pero si el candidato sí reporta certificaciones y el Job sí define habilidades técnicas, las certificaciones del CV se comparan semánticamente contra esas habilidades técnicas mediante un prompt específico. Este flujo de decisiones se resume en la Figura \ref{fig:flujo-comparacion-certificaciones}, y esta lógica se implementó dado una recomendación del evaluador de RR.HH. del modelo, que se detalla en secciones posteriores.

En \textbf{responsabilidades}, el problema es inverso: la descripción de trabajo sí trae una lista explícita de responsabilidades, pero el esquema estructurado del CV no tiene un campo dedicado a este concepto. Para no perder esta dimensión, se reutiliza la \textit{experiencia laboral} como entrada y la compara con las responsabilidades del puesto usando el prompt descrito en la Tabla \ref{tab:prompts-comp}. Así, el sistema puede estimar hasta qué punto las tareas realizadas por el candidato se alinean con lo que el rol exige, aun cuando dicha alineación no esté modelada como un campo de responsabilidades dentro del JSON del CV.
\subsubsection{Fase 3: Agregación y Scoring}

\noindent En esta fase, representada en la Figura \ref{fig:fase3-agregacion}, el sistema toma como entrada todos los resultados generados por los comparadores de la fase anterior (scores y justificaciones por experiencia, habilidades, educación, certificaciones, idiomas, ubicación y responsabilidades) y los consolida en un único análisis global. Esta etapa aplica un procedimiento ordenado que primero organiza los scores por aspecto, maneja explícitamente los casos con datos faltantes, calcula un score final de compatibilidad y, finalmente, genera un resumen explicativo que el usuario puede interpretar fácilmente. El resultado de este flujo es un JSON estructurado final que sintetiza el nivel de compatibilidad entre el candidato y la vacante, junto con la trazabilidad de cómo se llegó a ese resultado.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.35\linewidth]{Fase_Agregacion_Pipeline_Comparador.png}
    \caption{Fase 3: Agregación y scoring del motor de comparaciones}
    \label{fig:fase3-agregacion}
\end{figure}
\noindent La Figura \ref{fig:fase3-pesos} profundiza en el primer bloque de esta fase, mostrando cómo el motor de comparaciones aplica \textbf{pesos configurables} sobre cada aspecto evaluado. Para cada resultado parcial (por ejemplo, educación, experiencia, habilidades técnicas y blandas, certificaciones, idiomas o ubicación) se asocia un peso por defecto que refleja su importancia relativa en el cálculo del score global, aunque estos valores pueden ajustarse según las necesidades del proceso de selección. 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{Detalle_Pesos_Pipeline_Comparador.png}
    \caption{Detalle de pesos configurables por aspecto}
    \label{fig:fase3-pesos}
\end{figure}

\subsubsection{Calculo de Score Final}
\noindent A nivel de cálculo, cada aspecto evaluado \(i\) (experiencia, educación, habilidades, etc.) aporta un \textit{score} \(s_i \in [0,1]\) y cuenta con un peso configurable \(w_i > 0\). Si el usuario define pesos personalizados que no suman 1, el sistema los normaliza mediante
\[
\tilde{w}_i = \frac{w_i}{\sum_j w_j},
\]
de forma que siempre se cumple \(\sum_i \tilde{w}_i = 1\) antes de combinar los resultados.

\noindent Luego, se calcula un \textit{score} ponderado bruto considerando únicamente los aspectos con información válida (es decir, aquellos cuyo \textit{score} no es \(-1.0\)):
\[
S_{\text{raw}} = \sum_{i \in U} s_i \cdot \tilde{w}_i,
\]
donde \(U\) es el conjunto de aspectos utilizados y
\[
W_{\text{used}} = \sum_{i \in U} \tilde{w}_i
\]
representa la suma de pesos efectivamente activos. Para evitar penalizar al candidato por dimensiones sin datos, el sistema normaliza el resultado dividiendo por \(W_{\text{used}}\):
\[
S_{\text{final}} =
\begin{cases}
\dfrac{S_{\text{raw}}}{W_{\text{used}}}, & \text{si } W_{\text{used}} > 0,\\[6pt]
0, & \text{en caso contrario}.
\end{cases}
\]

\noindent Este valor \(S_{\text{final}}\) constituye el \textit{score} global de compatibilidad, el cual se almacena en el JSON final junto con el desglose por aspecto y el resumen explicativo generado por el motor.
\subsubsection{Generar resultado final}
\noindent Finalmente, el motor de comparaciones construye un objeto JSON de salida que consolida toda la información relevante para el usuario. Este resultado incluye el \textit{score} global \(S_{\text{final}}\), el detalle de scores por aspecto (experiencia, educación, habilidades, certificaciones, idiomas, ubicación y responsabilidades), las razones textuales generadas por los distintos prompts y una síntesis narrativa del nivel de ajuste entre el perfil del candidato y la vacante. De este modo, el sistema no solo entrega un valor numérico interpretable, sino también una explicación estructurada y trazable que facilita la toma de decisiones en el proceso de selección.

\section{Vista general del Frontend}
\subsection{Rol del frontend y alcance de la sección}
\noindent El frontend se concibió como una capa de presentación ligera cuyo objetivo principal es hacer accesible el motor de estructuración y comparación a usuarios no técnicos (reclutadores, analistas o investigadores). En lugar de profundizar en detalles de implementación o tecnologías específicas, esta sección se centra en describir las vistas clave de la interfaz y cómo éstas materializan el flujo de uso del sistema: desde la carga de información hasta la interpretación de los resultados de compatibilidad.

\subsection{Flujo general de navegación}
\noindent La navegación comienza en una \textbf{vista de inicio} que resume las principales acciones disponibles y guía al usuario a través del proceso. Como se muestra en la Figura \ref{fig:frontend-carga}, la pantalla presenta accesos rápidos para subir nuevos CVs, crear ofertas de trabajo y lanzar análisis, además de una breve guía de ``cómo empezar'' que explica el orden recomendado de los pasos.

\noindent A partir de esta vista inicial, el usuario puede acceder a tres grandes grupos de funcionalidades: (i) gestión de hojas de vida, (ii) gestión de descripciones de trabajo y (iii) análisis y revisión de resultados. Cada grupo cuenta con vistas de listado, formularios de creación y pantallas de detalle que permiten explorar la información estructurada generada por el backend.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{Vista_Inicio.png}
    \caption{Interfaz: vista de inicio del sistema}
    \label{fig:frontend-carga}
\end{figure}

\subsection{Gestión de Hojas de Vida}
\noindent La sección de hojas de vida permite cargar nuevos documentos PDF y consultar los que ya han sido procesados. La \textbf{vista de carga de CV} (Figura \ref{fig:ui-subir-cv}) guía al usuario en la selección del archivo y muestra mensajes claros durante el procesamiento. Una vez estructurado el documento, la \textbf{vista de listado de CVs} (Figura \ref{fig:ui-listar-cvs}) presenta cada candidato en forma de tarjeta, con opciones para acceder al detalle o eliminar registros que ya no sean relevantes.

\noindent Al seleccionar un candidato, el sistema muestra un conjunto de \textbf{vistas de detalle} organizadas por pestañas, donde se exponen las entidades extraídas por el motor de estructuración: información personal (Figura \ref{fig:ui-cv-info-personal}), educación (Figura \ref{fig:ui-cv-educacion}), experiencia laboral (Figura \ref{fig:ui-cv-experiencia}), habilidades técnicas (Figura \ref{fig:ui-cv-habilidades}), certificaciones (Figura \ref{fig:ui-cv-certificaciones}) e idiomas (Figura \ref{fig:ui-cv-idiomas}). Además, una vista adicional muestra el historial de análisis asociados a ese CV (Figura \ref{fig:ui-cv-analisis-realizados}), conectando directamente el perfil estructurado del candidato con las evaluaciones realizadas frente a distintas vacantes.

\subsection{Gestión de Descripciones de Trabajo}
\noindent De forma análoga, la interfaz ofrece un flujo dedicado para registrar y administrar descripciones de trabajo. La \textbf{vista de creación de oferta} (Figura \ref{fig:ui-crear-job}) permite pegar o escribir el texto libre de la vacante, que luego es enviado al backend para su estructuración. La \textbf{vista de listado de descripciones} (Figura \ref{fig:ui-listar-jobs}) organiza las ofertas existentes y facilita el acceso a su detalle o la eliminación de registros obsoletos.

\noindent En el detalle de cada oferta se muestran las secciones estructuradas relevantes (información general, requisitos, responsabilidades, beneficios, entre otras), como se observa en las Figuras \ref{fig:ui-job-informacion-general} y \ref{fig:placeholder}, y se habilita una pestaña específica de \textbf{``Top candidatos''} donde se visualiza el ranking de candidatos mejor posicionados para ese rol (Figura \ref{fig:ui-ranking}). Esta vista sirve como punto de entrada natural para explorar en profundidad los análisis individuales generados por el motor de comparaciones.

\subsection{Análisis de compatibilidad y resultados}
\noindent El tercer bloque funcional agrupa las vistas relacionadas con la ejecución y revisión de análisis. La \textbf{vista de análisis CV vs Job} (Figura \ref{fig:ui-analizar}) permite seleccionar un candidato y una oferta concreta, así como configurar, de manera sencilla, si se utilizarán pesos predeterminados o personalizados en la agregación de resultados. Tras lanzar el proceso, la interfaz muestra estados de carga hasta que el backend retorna el análisis completo.

\noindent Una vez disponible el resultado, el usuario puede consultarlo en una vista con dos niveles. En primer lugar, una \textbf{vista de resumen del análisis} (Figura \ref{fig:ui-resumen-analisis}) destaca el score global de compatibilidad y presenta un resumen textual generado por IA que sintetiza las principales fortalezas y brechas del candidato frente a la vacante. En segundo lugar, la \textbf{vista de resultados detallados y desglose por aspecto} (Figura \ref{fig:frontend-resultados}) profundiza en cada dimensión evaluada (experiencia, habilidades técnicas y blandas, educación, certificaciones, idiomas, ubicación y responsabilidades), mostrando tanto el score como la razón asociada a cada comparador.

\noindent Complementariamente, la aplicación incorpora una \textbf{vista de historial de análisis} (Figura \ref{fig:ui-historial-analisis}) donde se listan, en orden cronológico, las evaluaciones realizadas, permitiendo al usuario revisar rápidamente resultados pasados, acceder al detalle de cada uno o eliminarlos si ya no son necesarios.

\noindent Además, dado que el objetivo principal del sistema es facilitar la toma de decisiones en procesos de selección, el frontend refuerza los resultados numéricos con representaciones visuales. La \textbf{vista de gráfica de análisis} (Figura \ref{fig:ui-grafica-score}) muestra, para una oferta concreta, una gráfica de dispersión que relaciona el score obtenido por cada candidato con el porcentaje de criterios efectivamente evaluados, ayudando a identificar casos donde un score alto podría ser engañoso por basarse en poca información.

\section{Conclusión del capítulo}
\noindent En este capítulo se detalló cómo la arquitectura propuesta se materializa en una implementación concreta que conecta, de forma trazable, la carga de documentos, su estructuración mediante modelos de lenguaje y el cálculo de scores de compatibilidad. Se describieron las capas del backend y su interacción con el \textit{core} de procesamiento, los \textit{pipelines} de NLP para hojas de vida y descripciones de trabajo, así como el motor de comparaciones y su esquema de agregación ponderada de resultados. Finalmente, se mostró cómo el frontend orquesta estos componentes en un flujo de uso coherente y centrado en el usuario, permitiendo que la complejidad algorítmica del sistema se traduzca en interfaces comprensibles que apoyan la toma de decisiones en procesos de selección.