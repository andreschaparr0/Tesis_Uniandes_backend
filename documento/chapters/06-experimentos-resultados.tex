\chapter{Evaluación y Resultados}
\label{chap:evaluaciones}

\section{Diseño experimental}
\label{sec:diseno-experimental}

Esta sección detalla el diseño de las pruebas realizadas para validar la utilidad y precisión del sistema propuesto. El protocolo experimental se construyó para evaluar tanto la capacidad del sistema para interpretar información no estructurada como su competencia para emitir juicios de valor comparables a los de un reclutador humano.

\subsection{Visión general del protocolo de experimentación}

El proceso de validación se estructuró en torno a dos ejes fundamentales definidos en la metodología. En primer lugar, se evaluó la calidad de la \textbf{estructuración de datos}, verificando si los modelos de lenguaje lograban extraer y normalizar correctamente la información contenida en las hojas de vida (PDF) y las descripciones de trabajo (texto). Esta etapa es crítica, pues la fiabilidad de cualquier recomendación posterior depende directamente de la integridad de los datos de entrada.

En segundo lugar, se evaluó el desempeño del \textbf{motor de recomendación}. Para esto, se diseñó un escenario de prueba que simula procesos de selección reales, donde el sistema procesa un conjunto de candidatos frente a vacantes específicas. Los resultados generados (scores de compatibilidad, desgloses por aspecto y rankings) fueron sometidos a una revisión cualitativa por parte de un profesional de Recursos Humanos, quien contrastó el criterio de la inteligencia artificial con su propio juicio experto. Este enfoque mixto permite medir no solo la precisión técnica, sino la utilidad práctica de la herramienta como sistema de apoyo a la decisión.

\subsection{Delimitación del dominio: El nicho tecnológico}

Para garantizar la validez interna de las evaluaciones y permitir un análisis profundo de los resultados, el alcance del modelo se acotó específicamente al sector de tecnología y desarrollo de software. Esta decisión se fundamenta en el perfil académico del autor (Ingeniería de Sistemas y Computación), lo que otorga un criterio técnico sólido para validar si las correspondencias halladas entre habilidades (por ejemplo, frameworks, lenguajes de programación y herramientas) son semánticamente correctas.

\subsection{Conformación del dataset}

El conjunto de datos utilizado para las pruebas está compuesto por un total de 10 hojas de vida y 4 descripciones de trabajo, todas pertenecientes al sector tecnológico. Las hojas de vida fueron recolectadas mediante una convocatoria controlada entre conocidos y colegas del entorno académico, quienes autorizaron el uso de sus documentos con fines académicos.

La muestra de candidatos refleja el contexto universitario y de ingreso al mercado laboral, con una mayoría de participantes vinculados a la Universidad de los Andes. En términos de experiencia, se obtuvo una distribución equilibrada:
\begin{itemize}
    \item Cerca del 40\% corresponde a estudiantes de últimos semestres o recién egresados, cuyos perfiles se basan principalmente en proyectos académicos y prácticas profesionales.
    \item El 60\% restante corresponde a profesionales con experiencia que oscila entre perfiles junior y candidatos con hasta seis años de trayectoria en la industria.
\end{itemize}

Las 4 descripciones de trabajo se seleccionaron para cubrir distintos niveles dentro del desarrollo de software, buscando variedad en responsabilidades y en el nivel de experiencia solicitado. Para cada una de las dos empresas consideradas, se incluyó tanto una vacante orientada a candidatos con experiencia profesional como una oportunidad de prácticas dirigida a perfiles en formación. Esta combinación permitió evaluar cómo responde el modelo frente a ofertas que difieren en complejidad, nivel de detalle y expectativas técnicas, sin introducir sesgos hacia un único tipo de rol.

\section{Evaluación de estructuración}
\label{sec:evaluacion-estructuracion}

\subsection{Metodología de verificación técnica}
Esta fase de evaluación tiene como objetivo medir la fidelidad con la que el sistema transforma documentos no estructurados en objetos JSON. La evaluación de la estructuración es una tarea de verificación fáctica: comprobar si la información presente en el documento original fue capturada correctamente, si hubo omisiones o si el modelo alucinó datos inexistentes. Por esto mismo, esta etapa la evaluó una persona con conocimiento del contexto del proyecto (sin requerir especialidad en RR. HH.). 

Se procesaron las 10 hojas de vida y las 4 descripciones de trabajo a través de los pipelines de estructuración descritos en el capítulo anterior. Posteriormente, se realizó una revisión manual ítem por ítem, comparando el contenido del archivo fuente (PDF o texto) contra el resultado estructurado generado por el sistema.

\subsection{Instrumentos y métricas de calidad}
Para evaluar de forma consistente la calidad de la estructuración, se definieron dos instrumentos análogos, uno para hojas de vida y otro para descripciones de trabajo. En ambos casos, cada campo extraído se somete a una revisión manual donde se asigna un \textit{Score} porcentual (de 0\% a 100\%) que mide la completitud y precisión de la extracción, acompañado de una \textit{Razón} justificativa que explica el motivo del puntaje.

Para las hojas de vida, el instrumento evalúa siete dimensiones clave: información personal, educación, experiencia laboral, habilidades técnicas, habilidades blandas, certificaciones e idiomas. Por su parte, el instrumento para descripciones de trabajo amplía la evaluación a diez dimensiones, incorporando campos específicos de las vacantes como información básica, responsabilidades, ubicación y beneficios, además de los requisitos homólogos a los del CV (educación, experiencia, habilidades y certificaciones).

\subsection{Resultados de estructuración de hojas de vida}

Tras aplicar el instrumento de evaluación sobre las 10 hojas de vida, se obtuvieron un total de 70 resultados (7 rubros por cada uno de los 10 candidatos). El desempeño general del motor de estructuración fue altamente satisfactorio. A continuación, se presenta la distribución de los puntajes obtenidos:

\begin{table}[H]
    \centering
    \small
    \caption{Distribución de puntajes de estructuración de Hojas de Vida}
    \label{tab:distribucion-cv}
    \begin{tabular}{|l|c|l|}
    \hline
    \textbf{Rango de Score} & \textbf{Frecuencia} & \textbf{Descripción} \\ \hline
    100\% & 51 & Extracción perfecta \\ \hline
    80\% - 99\% & 12 & Errores menores de formato o incompletitud leve \\ \hline
    50\% - 79\% & 3 & Errores parciales o confusión de categorías \\ \hline
    20\% - 49\% & 1 & Error significativo de interpretación \\ \hline
    0\% - 19\% & 0 & Fallo total \\ \hline
    \end{tabular}
\end{table}

El análisis cualitativo de estos resultados permite identificar fortalezas claras y áreas de mejora específicas en el pipeline de procesamiento:

\subsubsection*{Desempeño por rubros y hallazgos clave}

Las Tablas \ref{tab:resultados-cv-1} y \ref{tab:resultados-cv-2} presentan la matriz completa de evaluación para los 10 candidatos, detallando el score y la razón en cada rubro.

\begin{table}[H]
    \centering
    \scriptsize
    \caption{Resultados de estructuración de Hojas de Vida (Candidatos 1-5)}
    \label{tab:resultados-cv-1}
    \setlength{\tabcolsep}{3pt}
    \begin{tabular}{|l|p{2.2cm}|p{2.2cm}|p{2.2cm}|p{2.2cm}|p{2.2cm}|}
    \hline
    \textbf{Rubro} & \textbf{Andrés Chaparro} & \textbf{Carlos Santoyo} & \textbf{Gabriel Gómez} & \textbf{Javier Barrera} & \textbf{Juan E. López} \\ \hline
    \textbf{Personal} & \textbf{100\%} \newline Bien & \textbf{95\%} \newline Faltaron símbolos en el correo & \textbf{100\%} \newline Bien & \textbf{95\%} \newline Faltaron símbolos en el correo & \textbf{95\%} \newline Faltaron símbolos en el correo \\ \hline
    \textbf{Educación} & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{60\%} \newline Puso mal la univ. (Andes vs Javeriana) & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien \\ \hline
    \textbf{Experiencia} & \textbf{100\%} \newline Bien & \textbf{80\%} \newline Faltó poner que call centers fueron bilingües & \textbf{35\%} \newline Confundió proy. con exp. y añadió de más & \textbf{100\%} \newline Bien & \textbf{90\%} \newline Faltó especificar clase de monitoría \\ \hline
    \textbf{Tech Skills} & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien \\ \hline
    \textbf{Soft Skills} & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{80\%} \newline Bien pero faltaron algunas & \textbf{100\%} \newline Bien \\ \hline
    \textbf{Certif.} & \textbf{100\%} \newline Bien & \textbf{90\%} \newline Puso año 2023 no aclarado en CV & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien \\ \hline
    \textbf{Idiomas} & \textbf{100\%} \newline Bien & \textbf{70\%} \newline Puso el lenguaje bilingüe & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien \\ \hline
    \end{tabular}
\end{table}

\begin{table}[H]
    \centering
    \scriptsize
    \caption{Resultados de estructuración de Hojas de Vida (Candidatos 6-10)}
    \label{tab:resultados-cv-2}
    \setlength{\tabcolsep}{3pt}
    \begin{tabular}{|l|p{2.2cm}|p{2.2cm}|p{2.2cm}|p{2.2cm}|p{2.2cm}|}
    \hline
    \textbf{Rubro} & \textbf{Juanchito Bernal} & \textbf{Julián Galindo} & \textbf{María Ramírez} & \textbf{Stiven Viedman} & \textbf{William Xavier} \\ \hline
    \textbf{Personal} & \textbf{95\%} \newline Faltaron símbolos en el correo & \textbf{95\%} \newline Faltaron símbolos en el correo & \textbf{95\%} \newline Faltaron símbolos en el correo & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien \\ \hline
    \textbf{Educación} & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien \\ \hline
    \textbf{Experiencia} & \textbf{50\%} \newline Correcta pero añadió proyectos portafolio & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien \\ \hline
    \textbf{Tech Skills} & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{50\%} \newline Capta todas pero pone de más \\ \hline
    \textbf{Soft Skills} & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{80\%} \newline No puso, se podría intuir & \textbf{80\%} \newline No puso, se podría intuir & \textbf{100\%} \newline Bien \\ \hline
    \textbf{Certif.} & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{50\%} \newline Puso cursos de educ. como certif. \\ \hline
    \textbf{Idiomas} & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{70\%} \newline No hay, se puede intuir \\ \hline
    \end{tabular}
\end{table}

\begin{itemize}
    \item \textbf{Habilidades Blandas (Soft Skills):} En la mayoría de los casos, el sistema logró inferir correctamente habilidades implícitas que no estaban listadas textualmente. Sin embargo, en 3 de los 10 casos, el modelo fue excesivamente conservador y no reportó habilidades que, aunque no explícitas, podrían haberse intuido del contexto, resultando en puntajes del 80\%.
    
    \item \textbf{Experiencia Laboral:} Este fue el rubro que presentó los desafíos más complejos. Si bien la mayoría de extracciones fueron correctas (100\%), el modelo mostró una tendencia a alucinar o sobre-interpretar información en perfiles junior. En casos específicos como el de Gabriel Gómez (35\%) o Juanchito Bernal (50\%), el sistema clasificó proyectos académicos de portafolio o voluntariados como experiencia laboral formal. Aunque semánticamente relavante, esto constituye un error estructural que infla la trayectoria del candidato al mezclar experiencia real con académica.
    
    \item \textbf{Información Personal y Educación:} Estos campos mostraron la mayor estabilidad. Los errores encontrados fueron marginales (scores del 95\%), limitándose principalmente a detalles de formato, como la omisión de símbolos en correos electrónicos (observado en 5 candidatos) o, en un único caso, la atribución errónea de la universidad en un título de pregrado.
    
    \item \textbf{Habilidades Técnicas y Certificaciones:} La extracción fue precisa en casi la totalidad de la muestra (generalmente 100\%). Se registró un caso aislado (William Xavier, 50\%) donde el modelo interpretó cursos listados en educación como certificaciones independientes, y otro donde incluyó habilidades técnicas excedentes.
    
    \item \textbf{Idiomas:} El desempeño fue sólido (mayoría 100\%), con excepciones puntuales relacionadas con la inferencia del lenguaje ``bilinguismo'' o la falta de deducción del idioma nativo cuando este no se declaraba explícitamente.

\end{itemize}

En conclusión, el motor de estructuración demostró una alta fiabilidad para los fines del sistema de recomendación, con una tasa de éxito superior al 90\% en la mayoría de los campos. Los errores identificados, principalmente en la distinción entre proyectos y experiencia laboral, son consistentes con la ambigüedad propia de los perfiles junior en el sector tecnológico.

\subsection{Resultados de estructuración de descripciones de trabajo}
La evaluación de la estructuración de las descripciones de trabajo (Jobs) se realizó sobre 4 vacantes distribuidas entre las empresas Pragma y Sezzle. Se obtuvieron un total de 40 puntos de control (10 rubros por vacante). Al igual que con las hojas de vida, los resultados fueron predominantemente positivos, con una alta incidencia de extracciones perfectas.

\begin{table}[H]
    \centering
    \small
    \caption{Distribución de puntajes de estructuración de Descripciones de Trabajo}
    \label{tab:distribucion-jobs}
    \begin{tabular}{|l|c|}
    \hline
    \textbf{Rango de Score} & \textbf{Frecuencia} \\ \hline
    100\% & 30 \\ \hline
    80\% - 99\% & 8 \\ \hline
    50\% - 79\% & 0 \\ \hline
    20\% - 49\% & 1 \\ \hline
    0\% - 19\% & 1 \\ \hline
    \end{tabular}
\end{table}

A continuación, la Tabla \ref{tab:resultados-jobs} presenta el detalle de la evaluación.

\begin{table}[H]
    \centering
    \scriptsize
    \caption{Resultados detallados de estructuración de Descripciones de Trabajo}
    \label{tab:resultados-jobs}
    \setlength{\tabcolsep}{3pt}
    \begin{tabular}{|l|p{3.0cm}|p{3.0cm}|p{3.0cm}|p{3.0cm}|}
    \hline
    \textbf{Rubro} & \textbf{Pragma Dev Java} & \textbf{Pragma Practicante} & \textbf{Sezzle AI Intern} & \textbf{Sezzle Jr Engineer} \\ \hline
    \textbf{Info. Básica} & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien \\ \hline
    \textbf{Responsab.} & \textbf{100\%} \newline Excelente, extrajo bien de "Retos" & \textbf{100\%} \newline Excelente, extrajo bien de "Retos" & \textbf{100\%} \newline Excelente, extrajo de "What You'll Do" & \textbf{100\%} \newline Excelente, extrajo de "What You'll Do" \\ \hline
    \textbf{Ubicación} & \textbf{100\%} \newline Correctas las 3 ubicaciones & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien \\ \hline
    \textbf{Educación} & \textbf{80\%} \newline Se desconoce pero infiere Comp. Science & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Infiere bien aunque no sea explícito & \textbf{100\%} \newline Infiere bien aunque no sea explícito \\ \hline
    \textbf{Experiencia} & \textbf{90\%} \newline Faltó exp. en caché (Redis/Memcached) & \textbf{80\%} \newline Pone "Desconocido" (correcto) pero mejor decir "no necesario" & \textbf{80\%} \newline Pone "Desconocido" (correcto) pero mejor decir "no necesario" & \textbf{20\%} \newline Solo pone años, no especifica en qué \\ \hline
    \textbf{Tech Skills} & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien \\ \hline
    \textbf{Soft Skills} & \textbf{100\%} \newline Intuye 3 habilidades con sentido & \textbf{100\%} \newline Intuye 3 habilidades con sentido & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien \\ \hline
    \textbf{Certif.} & \textbf{100\%} \newline Bien (Desconocido) & \textbf{100\%} \newline Bien (Desconocido) & \textbf{100\%} \newline Bien & \textbf{100\%} \newline Bien \\ \hline
    \textbf{Idiomas} & \textbf{90\%} \newline Infiere Español intermedio & \textbf{90\%} \newline Infiere Español intermedio & \textbf{90\%} \newline Infiere Inglés & \textbf{90\%} \newline Infiere Inglés \\ \hline
    \textbf{Beneficios} & \textbf{100\%} \newline Bien (Desconocido) & \textbf{10\%} \newline Confunde salario con beneficio & \textbf{100\%} \newline Bien (Desconocido) & \textbf{100\%} \newline Bien (Desconocido) \\ \hline
    \end{tabular}
\end{table}

Los hallazgos principales de esta evaluación indican:
\begin{itemize}
    \item \textbf{Responsabilidades y Ubicación:} Estos fueron los campos con el desempeño más sólido y constante, logrando una precisión del 100\% en todos los casos. El modelo demostró gran capacidad de adaptación semántica, identificando correctamente las secciones equivalentes a responsabilidades independientemente del título utilizado en la oferta.
    
    \item \textbf{Experiencia:} Al igual que en las hojas de vida, este rubro presentó las mayores dificultades. En las vacantes de practicantes, el modelo marcó correctamente la experiencia como Desconocida (score 80\%), aunque una interpretación ideal hubiera explicitado que "no se requiere experiencia". El error más significativo (20\%) ocurrió en la vacante junior de Sezzle, donde el sistema extrajo únicamente la cantidad de años requeridos, omitiendo el contexto técnico crucial sobre en qué tecnologías debía tenerse dicha experiencia.
    
    \item \textbf{Información Básica y Educación:} La extracción fue altamente confiable (mayoría 100\%). Destaca positivamente la capacidad del modelo para inferir requisitos educativos implícitos; por ejemplo, en las ofertas de Sezzle, aunque no se listaba una carrera específica, el sistema dedujo correctamente que el perfil requería estudios en Ciencias de la Computación o afines.
    
    \item \textbf{Habilidades Técnicas, Blandas y Certificaciones:} La precisión fue excelente en estos apartados. En habilidades técnicas y certificaciones no se registraron errores (100\%). En habilidades blandas, el sistema aplicó exitosamente la lógica de inferencia de la sub-seccion \ref{subsec:pipeline-jobs}, deduciendo tres competencias transversales pertinentes para cada cargo a partir de las responsabilidades descritas.
    
    \item \textbf{Idiomas:} Se validó exitosamente la funcionalidad de detección automática de la sub-seccion \ref{subsec:pipeline-jobs}. En los 4 casos, ante la ausencia de un requisito explícito, el modelo dedujo correctamente el idioma base de la oferta (Español para Pragma, Inglés para Sezzle) y asignó un nivel intermedio por defecto, garantizando que el criterio lingüístico no quedara vacío.
    
    \item \textbf{Beneficios:} Aunque en general el desempeño fue correcto, se registró un error puntual grave (10\%) en la vacante de practicante de Pragma. El sistema confundió el salario clasificándolo erróneamente como un beneficio, cuando este elemento salario deberia aparecer en la información basica, lo que revela una dificultad para distinguir matices contractuales específicos de la legislación laboral local.
\end{itemize}
\section{Evaluación del modelo}
\label{sec:evaluacion-modelo}

\subsection{Protocolo de validación experta y métricas comparativas}
\label{subsec:protocolo-validacion}

Para determinar si el sistema emite juicios de valor alineados con el criterio profesional, se diseñó una evaluación basada en cuatro análisis de procesos de selección. Cada análisis consistió en el análisis de una descripción de trabajo específica frente a un subconjunto de cinco hojas de vida seleccionadas del dataset, creando escenarios controlados de competencia por una vacante.

La validación cualitativa fue realizada por Juan Pablo Chaparro, profesional de Recursos Humanos con experiencia en reclutamiento. Su rol consistió en actuar como un juez y, posteriormente, como auditor del sistema. Para cada análisis, el experto analizó los mismos documentos que el algoritmo y generó su propia valoración. Las métricas de éxito se definieron en función de la convergencia entre el criterio humano y el artificial a través de tres dimensiones:

\begin{itemize}
    \item \textbf{Comparación de rankings:} Se contrasta el orden de idoneidad de los candidatos generado por el modelo frente al ranking construido por el evaluador humano. Esto permite medir si el sistema prioriza correctamente a los mejores perfiles.
    \item \textbf{Consistencia de puntajes:} Se evalúa la correlación entre el \textit{score} de compatibilidad calculado por el algoritmo y la valoración subjetiva (en escala 0-100) asignada por el experto.
    \item \textbf{Validación semántica de las razones:} El experto revisa las justificaciones textuales generadas por la IA para cada aspecto (ej. "¿Por qué la experiencia es compatible?"), calificando si la explicación es coherente, precisa y útil para la toma de decisiones.
\end{itemize}

\subsection{Fases de ejecución y refinamiento iterativo}
\label{subsec:fases-evaluacion}

Con el objetivo de asegurar no solo la evaluación sino también la mejora continua del prototipo, el proceso experimental se dividió en dos fases operativas:

\begin{itemize}
    \item \textbf{Fase 1:} Se ejecutó el primer análisis utilizando la vacante Junior Java Developer de la empresa Pragma. Los resultados de este primer análisis fueron sometidos a una sesión de revisión detallada con el experto de RR.\,HH. Esta etapa permitió identificar divergencias tempranas en la interpretación de ciertos criterios (particularmente en la gestión de certificaciones y habilidades), lo que derivó en ajustes puntuales a la lógica de los comparadores y a los pesos del sistema.
    
    \item \textbf{Fase 2:} Tras implementar las correcciones derivadas de la reunión de retroalimentación, se procedió a ejecutar los tres análisis restantes. En esta fase se consolidaron los resultados definitivos reportados en este capítulo, permitiendo medir el desempeño del sistema ya calibrado frente a escenarios de distinta complejidad (roles de practicante vs. roles junior).
\end{itemize}

\section{Resultados de la fase 1}
\label{subsec:resultados-fase1}

El primer análisis se realizó utilizando una vacante real de Desarrollador Java Junior para la empresa Pragma. El objetivo de esta fase no fue solo medir la precisión, sino estresar el modelo para identificar comportamientos divergentes respecto al juicio humano.

\subsection{Análisis de ranking y puntajes}

A nivel de ordenamiento (ranking), el sistema demostró un desempeño sobresaliente. A pesar de que las magnitudes de los puntajes difirieron, el modelo ordenó a los candidatos exactamente en la misma secuencia que el experto de RR.\,HH., identificando correctamente al mejor candidato (Gabriel Gómez) y discriminando adecuadamente a los perfiles con menor ajuste. La Tabla \ref{tab:ranking-fase1} presenta esta comparación. El detalle completo de los \textit{scores} por criterio y candidato puede consultarse en las Tablas \ref{tab:fase1-eval-parte1}, \ref{tab:fase1-eval-parte2} y \ref{tab:fase1-eval-parte3} del Apéndice de prompts, mientras que la Tabla \ref{tab:fase1-eval-resumen} resume los puntajes finales de modelo y RR.\,HH. para los cinco candidatos evaluados.

\textbf{Nota:} Los resultados completos de todos los análisis, incluyendo puntajes detallados por criterio, razones y comparaciones, están disponibles en formato interactivo en el siguiente \href{https://uniandes-my.sharepoint.com/:x:/r/personal/a_chaparrod_uniandes_edu_co/Documents/Evaluaci\%C3\%B3n\%20del\%20Modelo\%20(3).xlsx?d=w9dadb14c608a4cb699946d70bea075b7&csf=1&web=1&e=cmUJfP}{documento de Excel compartido}.

\begin{table}[H]
    \centering
    \small
    \caption{Comparación de Rankings - Fase 1 (Pragma Java Junior)}
    \label{tab:ranking-fase1}
    \begin{tabular}{|c|l|l|c|}
    \hline
    \textbf{Posición} & \textbf{Ranking Modelo (IA)} & \textbf{Ranking Experto (RR.HH.)} \\ \hline
    1 & Gabriel Gómez & Gabriel Gómez \\ \hline
    2 & Juanchito Bernal & Juanchito Bernal  \\ \hline
    3 & Andrés Chaparro & Andrés Chaparro  \\ \hline
    4 & Juan E. López & Juan E. López \\ \hline
    5 & Javier Barrera & Javier Barrera \\ \hline
    \end{tabular}
\end{table}

\subsubsection*{Hallazgos y discrepancias detectadas}

Posterior al análisis, se realizó una sesión de retroalimentación con el evaluador para analizar por qué, aunque el ranking coincidía, existían diferencias notables en la evaluación de ciertos rubros específicos. Se identificaron cinco hallazgos críticos:

\begin{itemize}
    \item \textbf{Sesgo por ``Datos No Evaluados'' (-1):} El modelo fue excesivamente literal. Si la descripción del trabajo no tenía una sección explícita de Certificaciones, Idiomas o Habilidades Blandas, el sistema marcaba estos rubros como \texttt{-1} (No Evaluado). El experto, en cambio, siempre evaluaba estos aspectos: intuía el idioma por la redacción de la oferta e infería habilidades blandas del contexto. Esto generó una brecha significativa de cobertura en la evaluación.
    
    \item \textbf{Rigurosidad en Educación:} El evaluador humano penalizó fuertemente a los candidatos que no habían culminado sus estudios (no graduados), considerándolo un criterio excluyente para el cargo. El modelo, aunque valoró la educación, fue más laxo al puntuar perfiles en curso.
    
    \item \textbf{Inconsistencia en Responsabilidades:} Se detectó un sesgo en la interpretación de experiencias académicas. Tanto el candidato Juan Esteban López como Andrés Chaparro listaban monitorias académicas; sin embargo, el modelo solo validó positivamente esta experiencia para Juan Esteban, ignorándola para Andrés, lo que evidenció una falta de robustez en la detección de roles equivalentes.
    
    \item \textbf{Fallas en Ubicación:} El comparador de ubicación falló sistemáticamente (0\% de acierto), incapaz de relacionar semánticamente las ubicaciones o de manejar la flexibilidad de trabajo remoto con la misma destreza que el humano.
    
    \item \textbf{Valoración de Certificaciones:} El experto indicó que, aunque una oferta no pida certificaciones explícitamente, la presencia de certificados relevantes en la HV (como AWS o Java) debe sumar puntos positivos como un diferenciador, algo que el modelo ignoraba si el campo de requisitos estaba vacío.
\end{itemize}

\subsection{Ajustes implementados para la Fase 2}

A partir de estos \textit{insights}, se realizaron modificaciones estructurales en el \textit{core} del sistema antes de proceder con los siguientes análisis:

\begin{enumerate}
    \item \textbf{Comparador de certificaciones mejorado:} Se modificó la lógica para que, en ausencia de requisitos de certificación explícitos, el sistema compare las certificaciones del candidato contra las habilidades técnicas requeridas. Este cambio se explica a mayor detalle en \ref{subsec:pipeline-comparacion}.
    \item \textbf{Detección automática de idioma:} Se implementó un paso previo que detecta el idioma de la oferta laboral. Si la oferta está en inglés (aunque no pida Inglés explícitamente), el sistema ahora infiere el requisito. Este cambio se explica a mayor detalle en \ref{subsec:pipeline-jobs}.
    \item \textbf{Inferencia de habilidades blandas:} Se añadió una capa de razonamiento que deduce las habilidades blandas implícitas en las responsabilidades del cargo, evitando que este rubro quede sin evaluar. Este cambio se explica a mayor detalle en \ref{subsec:pipeline-jobs}.
\end{enumerate}

\section{Resultados de la fase 2}
\label{subsec:resultados-fase2}

\subsection{Análisis: Vacante de Practicante en Desarrollo de Software}
\label{subsec:analisis-practicante}

Este escenario planteó un desafío particular: la evaluación de perfiles para una posición de práctica profesional. A diferencia de los roles senior, donde la experiencia laboral es determinante, en estos perfiles el reclutador humano suele priorizar la formación académica en curso, el potencial de aprendizaje y las habilidades blandas, siendo más flexible con la falta de experiencia laboral formal.

\subsubsection*{Comparación de Rankings}

Al contrastar el ordenamiento de candidatos, se observó una divergencia significativa entre el criterio del modelo y el del experto de RR.HH., llegando a una inversión casi total en los extremos del ranking, como se evidencia en la Tabla \ref{tab:ranking-fase2-practicante}.

\begin{table}[H]
    \centering
    \small
    \caption{Comparación de Rankings - Análisis 2.1 (Practicante)}
    \label{tab:ranking-fase2-practicante}
    \begin{tabular}{|c|l|l|}
    \hline
    \textbf{Posición} & \textbf{Ranking Modelo (IA)} & \textbf{Ranking Experto (RR.HH.)} \\ \hline
    1 & María Ramírez & Andrés Chaparro \\ \hline
    2 & Stiven Viedman & Carlos Santoyo  \\ \hline
    3 & Andrés Chaparro & Stiven Viedman  \\ \hline
    4 & William Xavier & William Xavier \\ \hline
    5 & Carlos Santoyo & María Ramírez \\ \hline
    \end{tabular}
\end{table}

Mientras que para el experto humano los candidatos más fuertes fueron Andrés Chaparro y Carlos Santoyo (debido a su perfil educativo), el modelo priorizó a María Ramírez, quien fue la candidata mas descartada por el humano (posición 5).

\subsubsection*{Análisis de puntajes y discrepancias}

A partir de la revisión cualitativa con el evaluador, se identificaron las causas raíz de estas discrepancias:

\begin{itemize}
    \item \textbf{Sesgo de Normalización (Caso María Ramírez):} La candidata María Ramírez presentaba una hoja de vida con muy poca información, lo que resultó en que muchos aspectos (Experiencia, Responsabilidades, Certificaciones) fueran marcados como \texttt{-1} (No evaluado). Debido a la lógica de normalización del sistema (explicada en la Sección \ref{chap:metodologia}), su puntaje final se calculó únicamente sobre los pocos aspectos presentes (principalmente Habilidades Técnicas e Idiomas), donde tuvo coincidencias altas. Matemáticamente obtuvo un 74\%, pero para el reclutador humano, la ausencia de información es un criterio de descarte (33\%), evidenciando una limitación del algoritmo al manejar perfiles incompletos.
    
    \item \textbf{Criterio de Experiencia en Practicantes:} El experto humano valoró positivamente a candidatos como Andrés y Carlos por tener experiencia laboral previa y estar cursando carreras afines. El modelo, aunque puntuó bien la experiencia y habilidades técnicas de Andrés (95\% y 100\% respectivamente), lo penalizó severamente en el rubro de Educación (30\% vs 90\% del humano) y Ubicación (0\%). El modelo no logró interpretar con la misma flexibilidad que el humano que, para un practicante, estar "en curso" de una ingeniería es el estado ideal, y aplicó criterios de titulación más rígidos.
    
    \item \textbf{Persistencia del error de Ubicación:} A pesar de los ajustes, el comparador de ubicación continuó fallando (0\% en la mayoría de casos) al no lograr correlacionar ciudades implícitas o regiones cercanas con la misma destreza que el humano, o debido a la falta de especificación explícita en los CVs.
\end{itemize}

\subsection{Análisis: Vacante Sezzle A.I. Engineering Intern}
\label{subsec:analisis-sezzle-intern}

El segundo análisis de la Fase 2 evaluó el desempeño del sistema en una vacante internacional para un rol de pasantía en Inteligencia Artificial. Al igual que en el caso anterior, este rol privilegia el potencial y la formación académica por encima de la experiencia laboral extensa, pero con un componente técnico mucho más exigente en términos de herramientas modernas (Python, SQL, Cloud).

\subsubsection*{Comparación de Rankings}

En este caso, se observó una alineación más sólida en la parte superior de la tabla entre el modelo y el experto humano. Ambos sistemas de evaluación identificaron a Julián Galindo como el candidato más fuerte, aunque hubo discrepancias en el ordenamiento de los candidatos intermedios.

\begin{table}[H]
    \centering
    \small
    \caption{Comparación de Rankings - Análisis 2.2 (Sezzle AI Intern)}
    \label{tab:ranking-fase2-sezzle-intern}
    \begin{tabular}{|c|l|l|}
    \hline
    \textbf{Posición} & \textbf{Ranking Modelo (IA)} & \textbf{Ranking Experto (RR.HH.)} \\ \hline
    1 & Julián Galindo & Julián Galindo \\ \hline
    2 & Andrés Chaparro & Juan Esteban López \\ \hline
    3 & Juan Esteban López & Andrés Chaparro \\ \hline
    4 & Javier Barrera & Carlos Santoyo \\ \hline
    5 & Carlos Santoyo & Javier Barrera \\ \hline
    \end{tabular}
\end{table}

\subsubsection*{Análisis de puntajes y discrepancias}

A partir de la revisión cualitativa con el evaluador, se identificaron las causas raíz de estas discrepancias:

\begin{itemize}
    \item \textbf{Mejora en Skills Técnicos y Blandos:} El evaluador destacó que el modelo realizó un análisis muy preciso de las habilidades técnicas y blandas, así como de las certificaciones. Las razones generadas por la IA fueron coherentes con el juicio experto, identificando correctamente las brechas en tecnologías específicas.
    
    \item \textbf{Confusión por Modalidad Remota:} El comparador de ubicación falló consistentemente (0\% en los 5 casos). El error se atribuye a que la vacante especificaba la ubicación como ``Colombia, Remote``. El modelo, al no encontrar una coincidencia exacta de ciudad en las hojas de vida (que listan ciudades específicas como Bogotá), no logró resolver la relación de contención geográfica implícita.
    
    \item \textbf{Penalización de Experiencia en Pasantías:} El experto humano indicó que, para esta vacante de practicante, la experiencia laboral no era un factor crítico, priorizando la educación en curso. El modelo, sin embargo, asignó puntajes medios (alrededor del 50\%) en experiencia, señalando la falta de roles previos similares. Aunque técnicamente correcto, esto redujo el promedio general de los candidatos fuertes frente al criterio humano, que fue más indulgente en este rubro.
\end{itemize}


\subsection{Análisis: Vacante Sezzle Junior Software Engineer}
\label{subsec:analisis-sezzle-junior}

El tercer y último análisis se centró en un rol Junior de Ingeniería de Software. A diferencia de las pasantías, este perfil sí requiere experiencia profesional (típicamente 1-3 años) y título profesional, lo que permitió evaluar cómo el sistema maneja criterios de descarte más estrictos.

\subsection*{Comparación de Rankings}

En este escenario, el sistema alcanzó su mayor nivel de precisión en el ranking, coincidiendo perfectamente con el experto humano en la identificación del mejor candidato (Juanchito Bernal) y manteniendo una coherencia notable en el resto de la tabla, salvo por una inversión en las posiciones intermedias.

\begin{table}[H]
    \centering
    \small
    \caption{Comparación de Rankings - Análisis 2.3 (Sezzle Junior Dev)}
    \label{tab:ranking-fase2-sezzle-junior}
    \begin{tabular}{|c|l|l|}
    \hline
    \textbf{Posición} & \textbf{Ranking Modelo (IA)} & \textbf{Ranking Experto (RR.HH.)} \\ \hline
    1 & Juanchito Bernal & Juanchito Bernal \\ \hline
    2 & Andrés Chaparro & Gabriel Gómez \\ \hline
    3 & Gabriel Gómez & Stiven Viedman \\ \hline
    4 & Stiven Viedman & Andrés Chaparro \\ \hline
    5 & Juan Esteban López & Juan Esteban López \\ \hline
    \end{tabular}
\end{table}


A partir de la revisión cualitativa con el evaluador, se identificaron las causas raíz de estas discrepancias:


\begin{itemize}
    \item \textbf{Penalización por "No Graduado":} La mayor divergencia se dio con el candidato Andrés Chaparro (+28\%). Mientras el modelo valoró sus habilidades (57\%), el experto humano lo castigó severamente (29\%) por no haber culminado sus estudios, considerándolo un criterio de descarte (knock-out) para una posición Junior full-time, a diferencia de una pasantía.
    
    \item \textbf{Fenómeno de Sobrecalificación:} El candidato Gabriel Gómez, quien posee un perfil senior, fue puntuado por el humano con un 64\%, dejándolo en segundo lugar. El reclutador indicó que, aunque técnicamente apto, su exceso de experiencia podría implicar expectativas salariales altas, haciéndolo "sobrecalificado". El modelo, al no tener contexto salarial, simplemente evaluó el ajuste técnico, otorgándole un puntaje competitivo (51\%) aunque inferior al candidato ideal, mostrando una alineación interesante con la intuición humana por razones distintas.
    
    \item \textbf{Precisión en Idiomas:} El desempeño del comparador de idiomas fue validado positivamente. El experto notó que la calificación del modelo variaba acordemente al nivel detectado, alineándose con su propio criterio.
    
    \item \textbf{Persistencia del error de Ubicación:} Al igual que en el caso anterior, la ubicación "Remote" generó falsos negativos en todos los candidatos, confirmando la necesidad de mejorar la lógica de inferencia geográfica para modalidades de teletrabajo.
\end{itemize}

\section{Discusión general de resultados}

La ejecución de las dos fases experimentales permite concluir que el sistema propuesto logra un nivel de competencia significativo como herramienta de apoyo a la decisión. En términos de ranking, el modelo demostró una capacidad robusta para identificar a los candidatos más fuertes, coincidiendo con el experto humano en el primer lugar en 2 de los 3 análisis de la Fase 2.

Sin embargo, las discrepancias en los puntajes absolutos revelan que el juicio humano incorpora reglas de negocio tácitas (como la penalización severa por no estar graduado en roles Junior o la devaluación de la experiencia en roles de pasante) que el modelo, en su configuración actual, no pondera con la misma agresividad. Mientras el sistema evalúa la compatibilidad semántica pura, el reclutador evalúa la viabilidad de contratación.

A pesar de estas diferencias, la validación experta confirmó que los desgloses explicativos (razones) generados por la IA son coherentes y útiles, ofreciendo una transparencia que facilita al reclutador entender por qué un candidato obtuvo cierto puntaje, permitiéndole ajustar la decisión final con su propio criterio estratégico.
